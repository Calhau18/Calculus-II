\documentclass{article}
\title{Resumos de \\ Cálculo Diferencial e Integral II}
\date{2020}
\author{João Rocha}

\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools, nccmath}
\usepackage{geometry}
\usepackage{graphicx}
 \geometry{
 a4paper,
 total={129mm,170mm},
 left=23mm,
 top=23mm,
 bottom=28mm,
 right=28mm,
 }

\begin{document}
\maketitle

\vspace*{\fill}
\textbf{AVISO}:\\ 
Este texto é essencialmente um resumo dos conhecimentos mais essenciais da cadeira de Cálculo II, não tendo portanto o objetivo de entrar por explicações em detalhe dos conceitos abordados. Desse modo, o objetivo principal deste documento é o de consulta, e não o de esclarecimento. No entanto, alguns temas são acompanhados de explicações breves, de forma a relembrar a intuição por trás dos mesmos. 
\newpage

\section{O espaço $\mathbb{R}^n$}
\subsection{Funções em $\mathbb{R}^n$}
A cadeira de Cálculo I centra-se no estudo de funções \textbf{reais de variável real}, isto é funções que fazem correspondências dos reais para os reais.\\
No entanto, isto revela-se frequentemente insuficente. Cálculo é frequentemente útil para analisar certos sistemas, e estes sistemas podem ter por vezes mais do que um variável "em jogo".\\
A cadeira de Cálculo II tenta então generalizar o estudo da função para situações em que há mais do que uma variável em consideração.\\
Definimos então o conjunto $\mathbb{R}^n$ como o conjunto dos pontos $x=(x_1, x_2, \cdots, x_n)$, com $x_1, x_2, \cdots , x_n \in \mathbb{R}$, tal como seria definido numa cadeira de Álgebra Linear. Como é de assumir que qualquer aluno a estudar cálculo com várias variáveis está familiarizado com o conceito de $\mathbb{R}^n$ não vamos entrar em mais detalhe/formalidades e assumir que $\mathbb{R}^n$ tem as propriedades axiomáticas como definidas numa cadeira de Álgebra Linear.\\
Definimos uma \textbf{função vetorial de variável vetorial} como qualquer transformação que faz corresponder a cada elemento de um conjunto $D \subset \mathbb{R}^n$ um e um só elemento de $\mathbb{R}^m$ ($m,n \in \mathbb{N}$).\\
Para realizar o estude de funções vetoriais, é extremamente importante a noção de limite. Como esta noção depende da noção de distância, começamos por definir este conceito:
\begin{itemize}
	\item O \text{módulo} de um ponto (ou vetor) em $\mathbb{R}^n$ é dado (usualmente) por $||x|| = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}$ em que $x_1, \cdots , x_n$ são as coordenadas de $x$.
	\item A \textbf{distância} entre $x, y \in \mathbb{R}^n$ é dada por $||x-y||$.
\end{itemize}

\subsection{Topologia de $\mathbb{R}^n$}
A noção de distância em $\mathbb{R}^n$ permite-nos extender alguns conceitos a $\mathbb{R}^n$ que permitem definir a estrutura topológica deste congunto.\\
Começamos com um dos conceitos mais fundamentais: o de vizinhança. Definimos uma \textbf{bola} de raio $\epsilon \in \mathbb{R}^+$ e centro $a \in \mathbb{R}^n$ como o conjunto $B_\epsilon(a) = \{ x \in \mathbb{R}^n : ||x-a|| < \epsilon \}$. É evidente que o conceito de bola é uma extensão do conceito de vizinhançaem $\mathbb{R}^n$, que não passa de uma bola uni-dimensional.\\
Com este conceito, podemos então classificar conjuntos de forma semelhande ao feito em CDI1:
\begin{itemize}
\item $a$ é um \textbf{ponto interior} de $A$ se existe $r$ tal que $B_r(a) \subset A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto exterior} de $A$ se existe $r$ tal que $B_r(a) \subset \mathbb{R}^n/A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto fronteiriço} de $A$ se não é interior nem exterior a $A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto aderente} a $A$ se para qualquer $r$, $B_r(a) \cap A \neq \emptyset$ \vspace{-0.8mm}
\end{itemize}
e chamamos: \vspace{-0.8mm}
\begin{itemize}
\item \textbf{Interior} de $A$ ($int \, A$) ao conjunto de pontos interiores de A \vspace{-0.8mm}
\item \textbf{Exterior} de $A$ ($ext \, A$) ao conjunto de pontos exteriores de A \vspace{-0.8mm}
\item \textbf{Fronteira} de $A$ ao ($\partial A$) conjunto de pontos fronteirições de A \vspace{-0.8mm}
\item \textbf{Fecho} ou \textbf{aderência} de $A$ ($\overline{A}$) ao conjunto de pontos aderentes de A ($\overline{A}=int \, A \cup \partial A$) \vspace{-0.8mm}
\end{itemize}
Observe-se que para qualquer $A \subset \mathbb{R}^n$, temos que 
$int \, A \cup \partial A \cup ext \, A = \mathbb{R}^n$ e $int \, A \cap \partial A \cap ext \, A = \emptyset$.\\
Um conjunto $A \in \mathbb{R}$ diz-se: \vspace{-0.8mm}
\begin{itemize}
\item \textbf{aberto} se $A= int \, A$ \vspace{-1mm}
\item \textbf{fechado} se $A= \overline{A}$ ($\mathbb{R}/A$ é aberto ou $\partial A \subset A$) \vspace{-0.8mm}
\item Um conjunto $A$ diz-se \textbf{limitado} se houver $x \in \mathbb{R}$ e $R \in \mathbb{R}^+$ tal que $A \subset B_R(x)$.
\item \textbf{compacto} se é fechado e limitado \vspace{-0.8mm}
\end{itemize}
A interseção/união de uma família de conjuntos abertos/fechados é também aberto/fechado.

\subsection{Sucessões}
Recorda-se que uma sucessão é essencialmente uma bijeção/correspondência entre um conjunto $\{ u_n: n \in \mathbb{N}^+\}$ e $\mathbb{N}^+$.
Seja $u_n$ uma sucessão de termos em $\mathbb{R}^n$. Observa-se que cada coordenada de $u_n$ descreve ela própria um sucessão de termos em $\mathbb{R}^n$. Assim, para cada $j \leq m$ damos o nome de \textbf{sucessões coordenadas} às sucessões $(u_{j_n})$ cujo termo de ordem $k$ corresponde à $j$-ésima coordenada de $u_k$.\\
Diz-se que uma sucessão $(u_n) \subset \mathbb{R}^n$ tende/converge para $u \in \mathbb{R}^n$ (e escreve-se $u_n \to u$) se e só se, para qualquer $\epsilon \in \mathbb{R}^+$ existe $p \in \mathbb{N}^+$ tal que $u_n \in B_\epsilon(u)$ para todo o $n>p$. É fácil de ver que esta definição é equivalente a verificar se a sucessão $d_n = || u_n - u ||$ é infinitesimal. Uma sucessão que convirja para $u \in \mathbb{R}^n$ diz-se \textbf{convergente}.\\
Note-se que as definições a cima enunciadas de convergência são pouco práticas. De facto, é bastante mais prático usar o seguinte facto:\\
Uma sucessão $(u_n)$ converge para $a = (a_1, a_2, \cdots , a_n) \in \mathbb{R}^n$ se e só se as sucessões coordenadas $u_{j_n}$ tendem para $a_j$ para todo o $j \in \{ 1,2, \cdots , n \}$. É então fácil verificar que o limite de uma sucessão em $\mathbb{R}^n$ é único (se existir).\\
Observe-se que qualquer sucessão de termos em $X \in \mathbb{R}^n$ tem limite na aderência de $X$. Então um conjunto é fechado se e só se qualquer sucessão de termos nesse conjunto tiver limite dentro do conjunto.\\
Diz-se ainda que uma sucessão é limitada se e só se o conjunto dos seus termos também o for. Tendo em conta os resultados a cima, é fácil concluir que uma sucessão é limitada se e só se as suas sucessões coordenadas também o forem. Verificam-se as seguintes propriedades:
\begin{itemize}
	\item Qualquer sucessão convergente é limitada.
	\item \textbf{Teorema de Bolzano-Weiestrass}: Qualquer sucessão limitada tem sub-sucessões convergentes.
\end{itemize}

\subsection{Continuidade}
Uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$ diz-se contínua num ponto $a \in \mathbb{R}^n$ se para qualquer bola de raio $\delta \in \mathbb{R}^+$ centrada em $f(a)$, existe uma bola de raio $\epsilon \in \mathbb{R}^+$ centrada em $a$ tal que 
$$x \in B_\epsilon(a) \, \cap \, D \Rightarrow f(x) \in B_\delta(f(a)) \quad (\forall \delta \in \mathbb{R}^+, \, \exists \epsilon \in \mathbb{R}^+ : ||x-a|| < \epsilon \vee x \in D \Rightarrow ||f(x)-f(a)|| < \delta)$$
Tal como em $\mathbb{R}$ (definição de Heine), podemos definir continuidade através de sucessões. Uma funçao $f : D \subset \mathbb{R}^n \to \mathbb{R}^m$ é contínua em $a \in D$ se e só se para qualquer sucessão $(u_n)$ de termos em $D$ convergente para $a$ se tem que $f(u_k) \to f(a)$.\\
Tal como nas sucessões, por vezes o estudo da continuidade de uma função torna-se mais simples se considerarmos as \textbf{funções coordenadas}. Seja uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$. Se considerarmos apenas o que $f$ faz à $k$-ésima coordenada dos objetos de $D$, obtemos uma função $f_k(x)$, de domínio em $\mathbb{R}$ a qual designamos de $k$-ésima função coordenada de $f$. Tal função $f$ será contínua num ponto $a \in D$ se e só se as $m$ funções coordenadas também o forem nas respetivas corrdenadas.\\
Propriedades de funções contínuas:
Se $f,g: \mathbb{R}^n \to \mathbb{R}^m$ forem contínuas em $a \in \mathbb{R}$ e $h: \mathbb{R}^m \to \mathbb{R}^l$ for contínua em $f(a) \in \mathbb{R}$, e $\alpha \in \mathbb{R}$ então:
\begin{itemize}
	\item $f \pm g$, $f \cdot g$, $||f||$, $\alpha f$, $f/g$ com $g(x) \neq 0$, são contínuas em $a$;
	\item $(h \circ f)$ é contínua em $a$;
\end{itemize}
Finalmente, introduzimos a noção de conexividade. Dois conjuntos $A,B \subset \mathbb{R}^n$ dizem-se \textbf{separados} se 
$$
A \cap \overline{B} = \overline{A} \cap B = \emptyset
$$
Um conjunto $C$ diz-se \textbf{conexo} se não houverem $A,B \subset C$ não-vazios tais que $A$ e $B$ são separados.\\
Teoremas sobre funções contínuas:
\begin{itemize}
	\item Uma função contínua transforma conjuntos compactos em conjuntos compactos;
	\item \textbf{Teorema de Weiestrass}: Uma função escalar contínua de domínio compacto em $\mathbb{R}^n$ tem máximo e mínimo;
	\item Uma função contínua transforma conjuntos conexos em conjuntos conexos;
	\item \textbf{Teorema do Valor Intermédio}: Seja $f : D \subset \mathbb{R}^n \to \mathbb{R}$ contínua de domínio conexo. Se $a,b \in f(D)$ com $b<a$ então $[a,b] \subset f(D)$.
\end{itemize}

\subsection{Limites}
Tal como em CDI-I, definimos o \textbf{prolongamento contínuo} de uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$ como a função contínua $\tilde{f}: D^* \subset \overline{D} \to \mathbb{R}^n$ tal que $\tilde{f}(x) = f(x)$ para $x \in D$ e $D^*$ corresponde ao conjunto dos pontos em $\overline{D}$ tais que $f$ é prolongável por continuidade nesses pontos.\\
Então, definimos o limite de $f$ em $a \in \mathbb{R}$ como o valor do prolongamento contínuo de $f$ nesse ponto.
$$
\lim_{x \to a} f(x) = \tilde{f}(x)
$$
O limite de $f$ só existe nos pontos prolongáveis por continuidade.\\
Equivalentemente temos que para uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$:
$$
\lim_{x \to a} f(x) = b
$$
se e só se
\begin{itemize}
	\item Para qualquer sucessão de termos em $D$ tal que $u_n \to a$ se verifica que $f(u_n) \to f(a)$;
	\item $\forall_{\delta \in \mathbb{R}^+}, \exists_{\epsilon \in \mathbb{R}^+}: x \in B_\epsilon(a) \cap D \Rightarrow f(x) \in B_\delta(b)$.
\end{itemize}
Note-se que para um limite existir num ponto $a$, este tem de ser igual em todas as curvas que passam por esse ponto. Nomeadamente, o limite de uma função em $a$ só pode existir se o limite existir e for igual segundo todas as retas por $a$ (note-se que o limite segundo uma reta é um limite em $\mathbb{R}$). A estes limites (segundo retas) dá-se o nome de \textbf{limites direcionais} segundo uma reta/vetor.
No entanto, e como é impossível verificar o limite de uma função segundo todas as curvas que passam por um ponto, é necessário um método para calcular um limite.\\
\textbf{Método das funções enquadradas}:\\
Sejam $f,g,h: \mathbb{R}^n \to \mathbb{R}^m$ definidas em $B_r(a)$ para $a \in \mathbb{R}^n, r \in \mathbb{R}^+$. Então:
$$
f(x) \geq g(x) \geq h(x) \quad \forall_{x \in B_r(a)} \Rightarrow \lim_{x \to a} f(x) \geq \lim_{x \to a} g(x) \geq \lim_{x \to a} h(x) 
$$
e nomeadamente, se $\lim_{x \to a} f(x) = \lim_{x \to a} h(x) = b$ temos que $\lim_{x \to a} g(x) = b$.

\section{Diferenciabilidade}
\subsection{A Derivada}
Vimos em CDI-I que, entre outras, uma possível definição de derivada de uma função $f$ num ponto $a$ ($f'(a)$) é tal que 
$$
f(x) = f(a) + f'(a)(x-a) + r(x)
$$
em que $r(x)$ é uma função resto tal que $\frac{r(x)}{x-a} \to 0$ quando $x \to a$.\\
Note-se que a função $g(x) = f(a) + f'(a)(x-a)$ é uma função afim. De facto, esta é a melhor aproximação afim da função $f$.\\ 
Definimos então a derivada de uma função $f$ num ponto $a$ como a transformação linear $Df(a)$ que melhor aproxima $f$ na vizinhança de $a$. Note-se que $f$ vai então ser diferenciável se e só se esta transformação linear existir. Nesse caso, temos que:
$$
f(x) = f(a) + Df(a)(x-a) + r(x)
$$
Note-se que isto significa que a função $g(x) = f(a) + Df(a)(x-a)$ será o hiper-plano tangente á função $f$ no ponto $a$ (nomeadamente, para funções de domínio em $\mathbb{R}$, o hiper-plano é uma reta - a reta tangente).\\
Como qualquer transformação linear, $Df(a)$ pode ser representado por uma matriz. Se $f: \mathbb{R}^n \to \mathbb{R}^m$, $Df(a)$ vai ser representado por uma matriz $m \times n$, a qual se dá o nome de \textbf{matriz Jacobiana}.\\
Para construir a matriz Jacobiana, vemos o que esta faz aos vetores canónicos. Considere-se então $e_k$, o $k$-ésimo vetor canónico de $\mathbb{R}^n$. Vemos que:
$$
f(a + te_k) = f(a) + Df(a)(te_k) + r(te_k) \Leftrightarrow
$$
$$
Df(a)e_k = \lim_{t \to 0} \frac{f(a + te_k)-f(a)}{t}
$$
De forma que a matriz Jacobiana será constituída por $n$ vetores coluna dados pelo limite a cima, avaliado para cada vetor canónico. A este limite dá-se o nome de \textbf{derivada parcial} de $f$ em $a$, em ordem à variável $x_k$. Observando que o limite em cima origina um vetor com $m$ coordenadas, correspondentes aos limites
$$
\lim_{t \to 0} \frac{f_j(a + te_k)-f_j(a)}{t}
$$
em que $f_j$ representa uma das $m$ funções coordenadas de $f$, obtemos então a matriz:\\
\begin{center}
$Df(a) = $
$\begin{bmatrix}
	\frac{\partial f_1}{\partial x_1}(a) & \frac{\partial f_1}{\partial x_2}(a) & \cdots & 	\frac{\partial f_1}{\partial x_n}(a) \\
	\\
	\frac{\partial f_2}{\partial x_1}(a) & \frac{\partial f_2}{\partial x_2}(a) & \cdots & 	\frac{\partial f_2}{\partial x_n}(a) \\
	\\
	\cdots & \cdots & \cdots & \cdots \\
	\\
	\frac{\partial f_m}{\partial x_1}(a) & \frac{\partial f_m}{\partial x_2}(a) & \cdots & 	\frac{\partial f_m}{\partial x_n}(a) \\
\end{bmatrix}$
\end{center}
A noção de derivada parcial pode ser generalizada para vetores que não os canónicos. Define-se \textbf{derivada direcional} segundo um vetor $v$ (caso exista) como:
$$
\frac{\partial f}{\partial v}(a) = \frac{\partial}{\partial t} f(a+tv) \Big|_{t=0} = \lim_{t \to 0} \frac{f(a+tv)-f(a)}{t}
$$
A derivada segundo qualquer vetor $v$ pode no entanto ser obtida por meio da matriz Jacobiana. Para uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$ diferenciável em $a$, temos que, para qualquer $v \in \mathbb{R}^n$:
$$
\frac{\partial f}{\partial v}(a) = Df(a) \cdot v
$$
($\frac{\partial f}{\partial v}(a)$ é a imagem de $v$ por $Df(a)$).\\
Então,
$$
\frac{\partial f}{\partial v}(a) = Df(a)\cdot v = \sum_{j=1}^n v_j \cdot Df(a)e_j = \sum_{j=1}^n v_j \frac{\partial f}{\partial x_j} (a)
$$
\subsection{Propriedades da derivada}
\begin{itemize}
	\item $f$ é diferenciável em $a$ se e só se todas as suas funções coordenadas o forem;
	\item Qualquer função diferenciável é contínua;
	\item A existência de todas as derivadas parciais num ponto não é condição suficiente para a existência de derivada nesse ponto; 
	\item A existência e continuidade de todas as derivadas num ponto é condição suficiente para a existência de derivada nesse ponto. Ou seja, qualquer função de derivada contínua é diferenciável.
	\item A combinação linear de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D(\alpha f+\beta g)(a)=\alpha Df(a)+\beta Dg(a)$$
	\item O produto de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D(fg)(a)=Df(a)g(a)+f(a)Dg(a)$$
	\item O quociente de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D\left(\frac{f}{g} \right)(a)=\frac{Df(a)g(a)-f(a)Dg(a)}{g(a)^2} $$
	\item Sejam $D \subset \mathbb{R}^n$ e $E \subset \mathbb{R}^m$ abertos tal que $f: D \to \mathbb{R}^m$ e $g: E \to \mathbb{R}^k$ são diferenciáveis e $f(D) \subset E$. Então $g \circ f: D \to \mathbb{R}^k$ é diferenciável e $$ D(g \circ f)(a) = Dg(f(a)) \cdot Df(a) $$
\end{itemize}
Atentemos nesta última propriedade. A derivada da composição de funções é dada por um produto matricial. Esta propriedade dá-nos uma forma de calcular derivadas parciais das funções coordenadas da função composta em função das derivadas parciais das funções que a compôem. Dadas funções $f: D \to \mathbb{R}^m$ e $g: E \to \mathbb{R}^k$ com $D \subset \mathbb{R}^n$ e $E \subset \mathbb{R}^m$ abertos e $f(D) \subset E$, temos que
$$
\frac{\partial (g \circ f)_i }{\partial x_j}(x) = \left[ D(g \circ f)(x) \right]_{i,j} = \sum_{l=1}^m \left[ Dg(f(x)) \right]_{i,l} \left[ Df(x) \right]_{l,j} = \sum_{l=1}^m \frac{\partial g_i}{\partial y_l}(f(x)) \cdot \frac{\partial f_l}{\partial x_j}(x)
$$
Esta regra é conhecida por \textbf{regra da cadeia}.\\

\subsection{Gradiente}
Concentrando-nos agora em campos escalares, vemos que para uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}$, a matriz jacobiana tem apenas uma linha. Desta forma, ela pode ser representada na forma vetorial. Ao vetor
$$
\nabla f(a) = \left( \frac{\partial f_1}{\partial x_1}(a) \quad \frac{\partial f_1}{\partial x_2}(a) \quad \cdots \quad \frac{\partial f_1}{\partial x_n}(a) \right)
$$
dá-se o nome de \textbf{gradiente} de $f$ em $a$. Desta forma, o gradiente de uma função escalar é um campo vetorial $\nabla f: D \subset \mathbb{R}^n \to \mathbb{R}^n$ que a cada ponto $x \in D$ faz corresponder o vetor $\nabla f(x)$.\\
Neste caso, vemos que a derivada duma função escalar $f$ num ponto $a$ segundo um vetor $v$ é dada pelo produto vetorial:
$$
\frac{\partial f}{\partial v}(a) = Df(a) \cdot v = \nabla f(a) \cdot v = || \nabla f(a) || \cdot ||v|| \cdot \cos \theta
$$
em que $\theta$ é o ângulo entre o vetor $v$ e o vetor $\nabla f(a)$. Como este valor é máximo quando $\theta = 0$, temos que o vetor gradiente dá-nos a direção e sentido de crescimento máximo de $f$ (em $a$).\\
Observe-se ainda que se $v \perp \nabla f(a)$ então a derivada de $f$ em $a$ segundo $v$ é nula.\\
Note-se que com os vetores linha da matriz jacobiana de uma função $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$ correspondem aos gradientes das funções coordenadas de $f$:
\begin{center}$
\renewcommand*{\arraystretch}{1.2}
Df(a) =
\begin{bmatrix}
\nabla f_1(a) \\
\nabla f_2(a) \\
\cdots \\
\nabla f_n(a) \\
\end{bmatrix}$
\end{center}

\subsection{Linhas, Conjuntos de Nível e Tangentes}
Dá-se o nome de \textbf{caminho} ou \textbf{trajetória} a uma função contínua $\gamma: I \to \mathbb{R}^n$ em que $I \subset \mathbb{R}$ é um intervalo. Ao conjunto de chegada de $\gamma$ dá-se o nome de \textbf{linha}.\\
Define-se um \textbf{vetor tangente} a um caminho $\gamma$ de classe $C^1$como o vetor dado pelo limite
$$
\gamma '(t) = \lim_{h \to 0} \frac{\gamma(t+h)-\gamma(t)}{h}
$$
Note-se que isto é apenas um reaproveitamento da ideia de aproximar a reta tangente por secantes em pontos cada vez menos distantes na linha.\\
Se $\Gamma$ for a linha definida por $\gamma$, e $t$ for um ponto no domínio de $\gamma$, a reta tangente a $\Gamma$ pelo ponto $\gamma (t)$ é a reta de equação $x = \gamma(t) + \lambda \gamma '(t)$, para $\lambda \in \mathbb{R}$. \\
Definimos agora um \textbf{conjunto de nível} de $f: D \subset \mathbb{R}^n \to \mathbb{R}$ como um conjunto da forma 
$$
S_c(f) = \{ x \in D: f(x)=c \}
$$
Seja $\gamma: I \subset \mathbb{R} \to \mathbb{R}^n$ um caminho cuja linha $\Gamma$ está contida num conjunto de nível $S_\alpha (f)$ e seja $t, t_0 \in I$ com $t \in V_\epsilon(t_0)$ ($\epsilon \in \mathbb{R}^+$). Como $\Gamma \subset S_\alpha(f)$, temos que $(f \circ \gamma) (t_0) = \alpha$. Então:
$$
\frac{\partial}{\partial t} (f \circ \gamma)(t_0) = 0 \Leftrightarrow \nabla f(\gamma(t_0)) \cdot \gamma'(t_0) = 0 \Leftrightarrow \nabla f(\gamma (t)) \perp \gamma'(t)
$$
Então, o gradiente de uma função num ponto de um conjunto de nível (dessa função) é sempre ortogonal a esse conjunto. Diz-se, para tais pontos $p$ na linha $\Gamma \subset S_\alpha (f)$ que o vetor $\nabla f(p)$ é \textbf{normal} a $\Gamma$ em $p$.\\ 
Note-se que esta observação permite-nos definir equações para planos. Seja $G_f$ o gráfico de uma função escalar $f: \mathbb{R}^{n-1} \to \mathbb{R}$, ou seja, $G_f = \{ (x_1, x_2, \cdots, x_n) \in \mathbb{R}^n : x_n = f(x_1, x_2, \cdots , x_{n-1}) \}$. Se considerarmos a função $F: \mathbb{R}^n \to \mathbb{R}$ definida por $F(x) = x_n - f(x_1, x_2, \cdots , x_{n-1})$, temos que $G_f = S_0(F)$, de forma que o plano tangente a $G_f$ por um ponto $p \in D_f$ tem vetor normal 
$$
\nabla F(p) = \left( -\frac{\partial f}{\partial x_1}(p), -\frac{\partial f}{\partial x_2}(p), \cdots , -\frac{\partial f}{\partial x_{n-1}}(p), 1 \right)  
$$
Conclui-se então que o plano tangente a $f$ por um ponto $f(p)$ é dada por
$$
x_n = f(p) + \frac{\partial f}{\partial x_1}(p)(x_1-p_1) + \frac{\partial f}{\partial x_2}(p)(x_2-p_2) + \cdots + \frac{\partial f}{\partial x_{n-1}}(p)(x_{n-1}-p_{n-1}) 
$$

\subsection{Derivadas de Ordem Superior}
Para qualquer $D \subset \mathbb{R}^n$ aberto e um campo escalar $f \in C^1(D)$, temos que as derivadas parciais $\frac{\partial f}{\partial x_k}$ ($k \in \{ 1, 2, \cdots, n \}$) são também campos escalares definidos em $D$. Se estas funções forem também elas diferenciáveis, podemos definir as \textbf{derivadas de segunda ordem} de $f$:
$$
\frac{\partial}{\partial x_j} \left( \frac{\partial f}{\partial x_i} \right) = \frac{\partial ^2 f}{\partial x_j x_i}
$$
Mais genericamente, para indices $i_1, i_2, cdots , i_k \in \{ 1, 2, \cdots , n \}$, designamos por derivada de ordem $k$ à função
$$
\frac{\partial ^k f}{\partial x_{i_1}x_{i_2} \cdots x_{i_k}}
$$
Se esta função estiver definida e for contínua em $D$, dizemos que $f$ é de classe $C^k$ em D, e escrevemos $f \in C^k(D)$. Se $f$ for de classe $C^k$ em $D$ para todo o $k \in \mathbb{N}$, então escreve-se que $f \in C ^\infty (D)$.\\

\textbf{Teorema de Schwartz}: Seja $f: D \subset \mathbb{R}^n \to \mathbb{R}^m$ de classe $C^2$ em $D$ aberto. Então
$$
\frac{\partial}{\partial x_j} \left( \frac{\partial f}{\partial x_i} \right) = \frac{\partial ^2 f}{\partial x_j x_i}
$$
Mais genericamente, se $\{ i_1, i_2, \cdots, i_k \}$ for um conjunto de índices e $\sigma$ for uma permutação desse conjunto, temos que
$$
\frac{\partial ^k f}{\partial x_{i_1} \partial x_{i_2} \cdots \partial x_{i_k}} = \frac{\partial ^k f}{\partial x_{\sigma(i_1)} \partial x_{\sigma(i_2)} \cdots \partial x_{\sigma(i_k)}}
$$
A notação mais frequente para escrever este tipo de derivadas é então
$$
\frac{\partial ^N f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \cdots \partial x_n ^{\alpha_n}}
$$
em que $\alpha_i$ representa o número de vezes que se diferencia em ordem à variável $x_i$ e $N = \sum_{i=0}^n \alpha_i$.

\subsection{Extremos e Teorema de Taylor}
Tal como anteriormente, para estudar o extremo de uma função num ponto, vamos considerar o que acontece a essa função de acordo com certas retas (analisar uma função segundo uma reta permite-nos transformar o estudo de uma função em $\mathbb{R}^n$ no estudo de uma função em $\mathbb{R}$).\\
Considere-se então a função $\gamma: \mathbb{R} \to \mathbb{R}^n$ definida por $\gamma (t) = a + th$. Desta forma, temos que $g(t) = f(\gamma(t))$ consiste nos valores que $f$ toma sobre a reta por $a$ de vetor diretor $h$. Temos que $f$ vai ter um extremo em $a$ se e só se $g$ tiver um extremo em $t=0$, pelo que $f$ tem um extremo se e só se
$$
g'(0) = (f \circ \gamma )' (0) = \nabla f(\gamma (0)) \cdot \gamma'(0) = \nabla f(a) h
$$
for nulo para qualquer vetor $h$. Conclui-se que $f$ tem um extremo em $a$ no interior do seu domínio se e só se:
$$
\nabla f(a)=0
$$
Aos pontos que satisfazem esta propriedade dá-se o nome de \textbf{pontos críticos} de $f$. Note-se que nem todos os pontos críticos são extremos da função. Aos pontos críticos de $f$ que não são extremos dessa função dá-se o nome de \textbf{pontos de sela}. Pode-se no entanto dizer que o conjunto dos extremos no interior do domínio de uma função está contido no conjunto dos pontos críticos dessa função.\\
Torna-se então necessário arranjar um método de distinguir os extremos dos pontos de sela de uma função. Para funções em $\mathbb{R}$ isto podia ser feito através do Teorema de Taylor. Voltamos então a restringir a análise da função aos valores que esta toma segundo uma reta, ou seja, voltamos a considerar a função $\gamma: \mathbb{R} \to \mathbb{R}^n$ definida por $\gamma (t) = a + th$, de forma que $f$ tem polinómio de Taylor segundo a reta definida por $h$:
$$
f(a+th) = f(a) + f'(a)t + \frac{1}{2!}f''(a)t^2 + ... + \frac{1}{n!} f^{(n)}(a)t^n + r_{n+1}(t)
$$
sendo que
$$
f'(a) = \sum_{j=1}^n \frac{\partial f}{\partial x_j}(a) h_j = \nabla f(a) h  \quad \quad \quad \quad 
f''(a) = \sum_{k=1}^n \sum_{j=1}^n \frac{\partial ^2 f}{\partial x_j x_k} (a) h_j h_k 
$$
$$
f'''(a) = \sum_{k,i,j =1}^n \frac{\partial ^3 f}{\partial x_i x_j x_k} (a) h_i h_j h_k
$$
e por aí em diante.\\
Note-se que a segunda derivada em $a$ pode ser escrita como um produto matricial $h^T \cdot D^2 f(a) \cdot h$ em que:
$$
D^2 f(a) = 
\renewcommand*{\arraystretch}{1.8}
\begin{bmatrix}
\frac{\partial ^2 f}{\partial x_1 ^2} (a) && \frac{\partial ^2 f}{\partial x_2 x_1} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n x_1} (a) \\
\frac{\partial ^2 f}{\partial x_1 x_2} (a) && \frac{\partial ^2 f}{\partial x_2^2} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n x_2} (a) \\
\cdots && \cdots && \cdots && \cdots \\
\frac{\partial ^2 f}{\partial x_1 x_n} (a) && \frac{\partial ^2 f}{\partial x_2 x_n} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n ^2} (a)
\end{bmatrix}
$$
A esta matriz dá-se o nome de \textbf{matriz Hessiana} de $f$ no ponto $a$. Esta representação da segunda derivada permite-nos usar conhecimento de Álgebra Linear para estudar os pontos críticos da função. Relembra-se que uma matriz se diz:
\begin{itemize}
	\item Definida positiva/negativa se todos os seus valores próprios forem, respetivamente, positivos/negativos;
	\item Semi-definida positiva/negativa se todos os seus valores próprios forem, respetivamente, não-negativos/não-positivos;
	\item Indefinida se tiver valores próprios positivos e negativos;
\end{itemize}
Então, para um ponto crítico de $f$, temos que:
$$
\frac{f(a+th)-f(a)}{t^2} = \frac{1}{2!}f''(a) + \frac{r_3(t)}{t^2} \Rightarrow \lim_{t \to 0} \frac{f(a+th)-f(a)}{t^2} = \frac{1}{2!}f''(a)
$$
pelo que $f(a+h)-f(a)$ tem o mesmo sinal que a segunda derivada de $f$. Como, segundo o teorema de Schwartz, a matriz Hessiana é sempre simétrica, e temos que a matriz Hessiana é diagonalizável. Então, há valor próprio $\lambda$ e vetor próprio $h$ associado a $\lambda$ tais que:
$$
f''(a) = h^T \cdot D^2 (a) \cdot h = h^T \cdot \lambda h = \lambda ||h||^2
$$
Pelo que, o sinal de $f(a+h)-f(a)$ é dado pelo sinal dos valores próprios da matriz Hessiana de $f$. Concluímos então que para $a$ no interior do domínio de um campo escalar $f$:
\begin{itemize}
	\item Se a Hessiana de $f$ em $a$ for definida positiva, então $a$ é um mínimo local;
	\item Se a Hessiana de $f$ em $a$ for definida negativa, então $a$ é um máximo local;
	\item Se a Hessiana de $f$ em $a$ for indefinida, então $a$ é um ponto em sela;
	\item Se $a$ é um mínimo local então a Hessiana de $f$ em $a$ é semi-definida positiva;
	\item Se $a$ é um máximo local então a Hessiana de $f$ em $a$ é semi-definida negativa;
\end{itemize}
Note-se que esta abordagem pode por vezes não funcionar. Nestes casos, é necessário estudar diretamente o valor de $f$ numa bola à volta de $a$.

\section{Integrabilidade}

\subsection{O Integral}
Relembra-se do Cálculo I que a integração teve como motivação o cálculo da área de baixo de funções. Isto foi alcançado definindo estruturas "elementares" para as quais este problema era trivial (funções constantes em intervalos), e aproximar todoso os outros casos por estruturas desse tipo. Tal como feito anteriormente nesta disciplina, vamos tentar reduzir o caso multidimensional ao caso unidimensional, já estudado. Para isso, começamos então de definir intervalos em $\mathbb{R}^n$:\\
Um conjunto $I \subset \mathbb{R}^n$ diz-se um \textbf{intervalo} se $I = I_1 \times I_2 \times \cdots I_n$ onde cada $I_j \subset \mathbb{R}$ é um intervalo em $\mathbb{R}$.\\
Observa-se que $I$ será aberto, fechado ou limitado se e só se todas as suas arestas $I_1, \cdots, I_n$ forem, respetivamente, abertas, fechadas ou limitado.
Note-se que um intervalo limitado em $\mathbb{R}^2$/$\mathbb{R}^3$ é um retângulo/paralelipipedo alinhado com os eixos coordenados. É então intuitivo definir a área de um intervalo da seguinte forma:\\
Se $I = I_1 \times I_2 \times \cdots \times I_n$ é tal que $s_i = \sup(I_i)$ e $i_i = \inf(I_i)$ existem para todo o $i \in \{1,2,\cdots n\}$, então o \textbf{volume} (n-dimensional) de $I$ é dado por
$$
V_n(I) = \prod_{i=1}^n (s_i-i_i)
$$
note-se que para esta definição é irrelevante se os intervalos em $\mathbb{R}$ são abertos ou fechados.\\
Agora que já temos as nossas estruturas elementares, estamos prontos para aproximar os restantes casos:\\
Relembre-se de CDI-I que uma partição de um intervalo $I$ é um conjunto de pontos $P(I) = \{ x_0, x_1, \cdots, x_k \}$ tal que $x_0 = \inf(I)$ e $x_n = \sup(I)$. A cada partição associa-se a decomposição $I = \bigcap_{i=0}^{k-1} [a_i, a_{i+1}]$.\\
Generaliza-se então este conceito para $\mathbb{R}^n$ considerando uma \textbf{partição} de um intervalo limitado $I = I_1 \times \cdots I_n \subset \mathbb{R}^n$ como o produto cartesiano $P(I) = P(I_1) \times P(I_2) \times \cdots \times P(I_n)$. A estas partições também estará associada uma \textbf{decomposição} de $I$, dada pelo produto cartesiano dos intervalos da decomposição de cada "aresta" de $I$. Assim, temos um mecanismo para aproximar área de uma função, tal como em cálculo I:\\
Dada uma partição $P(I)$ de um intervalo limitado $I \subset \mathbb{R}^n$, o conjunto $D_P$ dos intervalos da decomposição associada a $P$ e um campo escalar limitado $f: \mathbb{R}^n \to \mathbb{R}$, definimos então a soma inferior ($s_P(f)$) e soma superior ($S_P(f)$) de $f$ relativa a $P$ como (respetivamente):
$$
s_P(f) = \sum_{X \in D_P} \inf(f|_X) \cdot V_n(X)
$$
$$
S_P(f) = \sum_{X \in D_P} \sup(f|_X) \cdot V_n(X)
$$
De forma semelhante a CDI-I, podemos definir partições mais finas e sobrepostas para fundamentar que os seguintes valores existem:
$$
\underline{\int_I} f = \sup \{ s_p(f): \forall \, P(I) \}
$$
$$
\overline{\int_I} f = \inf \{ S_p(f): \forall \, P(I) \}
$$
Definimos então \textbf{integrabilidade à Riemann} da seguinte forma:\\
Um campo escalar $f: I \subset \mathbb{R}^n$ diz-se integrável à Riemann se e só se $\overline{\int_I} f = \underline{\int_I} f$. Neste caso dá-se o nome de \textbf{integral} de $f$ em $I$ ao valor:
$$
\int_I f = \overline{\int_I} f = \underline{\int_I} f
$$

\end{document}
