\documentclass{article}
\title{Resumos de \\ Cálculo Diferencial e Integral II}
\date{2020}
\author{João Rocha}
	
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools, nccmath}
\usepackage{geometry}
\usepackage{graphicx}
 \geometry{
 a4paper,
 total={129mm,170mm},
 left=23mm,
 top=23mm,
 bottom=28mm,
 right=28mm,
 }

\newcommand{\R}{\mathbb{R}}

\begin{document}
\maketitle

\vspace*{\fill}
\textbf{AVISO}:\\ 
Este texto é essencialmente um resumo dos conhecimentos mais essenciais da cadeira de Cálculo II, não tendo portanto o objetivo de entrar por explicações em detalhe dos conceitos abordados. Desse modo, o objetivo principal deste documento é o de consulta, e não o de esclarecimento. No entanto, alguns temas são acompanhados de explicações breves, de forma a relembrar a intuição por trás dos mesmos. 
\newpage

\section{O espaço $\R^n$}
\subsection{Funções em $\R^n$}
A cadeira de Cálculo I centra-se no estudo de funções \textbf{reais de variável real}, isto é funções que fazem correspondências dos reais para os reais.\\
No entanto, isto revela-se frequentemente insuficente. Cálculo é frequentemente útil para analisar certos sistemas, e estes sistemas podem ter por vezes mais do que um variável "em jogo".\\
A cadeira de Cálculo II tenta então generalizar o estudo da função para situações em que há mais do que uma variável em consideração.\\
Definimos então o conjunto $\R^n$ como o conjunto dos pontos $x=(x_1, x_2, \cdots, x_n)$, com $x_1, x_2, \cdots , x_n \in \R$, tal como seria definido numa cadeira de Álgebra Linear. Como é de assumir que qualquer aluno a estudar cálculo com várias variáveis está familiarizado com o conceito de $\R^n$ não vamos entrar em mais detalhe/formalidades e assumir que $\R^n$ tem as propriedades axiomáticas como definidas numa cadeira de Álgebra Linear.\\
Definimos uma \textbf{função vetorial de variável vetorial} como qualquer transformação que faz corresponder a cada elemento de um conjunto $D \subset \R^n$ um e um só elemento de $\R^m$ ($m,n \in \mathbb{N}$).\\
Para realizar o estude de funções vetoriais, é extremamente importante a noção de limite. Como esta noção depende da noção de distância, começamos por definir este conceito:
\begin{itemize}
	\item O \text{módulo} de um ponto (ou vetor) em $\R^n$ é dado (usualmente) por $||x|| = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}$ em que $x_1, \cdots , x_n$ são as coordenadas de $x$.
	\item A \textbf{distância} entre $x, y \in \R^n$ é dada por $||x-y||$.
\end{itemize}

\subsection{Topologia de $\R^n$}
A noção de distância em $\R^n$ permite-nos extender alguns conceitos a $\R^n$ que permitem definir a estrutura topológica deste congunto.\\
Começamos com um dos conceitos mais fundamentais: o de vizinhança. Definimos uma \textbf{bola} de raio $\epsilon \in \R^+$ e centro $a \in \R^n$ como o conjunto $B_\epsilon(a) = \{ x \in \R^n : ||x-a|| < \epsilon \}$. É evidente que o conceito de bola é uma extensão do conceito de vizinhançaem $\R^n$, que não passa de uma bola uni-dimensional.\\
Com este conceito, podemos então classificar conjuntos de forma semelhande ao feito em CDI1:
\begin{itemize}
\item $a$ é um \textbf{ponto interior} de $A$ se existe $r$ tal que $B_r(a) \subset A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto exterior} de $A$ se existe $r$ tal que $B_r(a) \subset \R^n/A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto fronteiriço} de $A$ se não é interior nem exterior a $A$ \vspace{-0.8mm}
\item $a$ é um \textbf{ponto aderente} a $A$ se para qualquer $r$, $B_r(a) \cap A \neq \emptyset$ \vspace{-0.8mm}
\end{itemize}
e chamamos: \vspace{-0.8mm}
\begin{itemize}
\item \textbf{Interior} de $A$ ($int \, A$) ao conjunto de pontos interiores de A \vspace{-0.8mm}
\item \textbf{Exterior} de $A$ ($ext \, A$) ao conjunto de pontos exteriores de A \vspace{-0.8mm}
\item \textbf{Fronteira} de $A$ ao ($\partial A$) conjunto de pontos fronteirições de A \vspace{-0.8mm}
\item \textbf{Fecho} ou \textbf{aderência} de $A$ ($\overline{A}$) ao conjunto de pontos aderentes de A ($\overline{A}=int \, A \cup \partial A$) \vspace{-0.8mm}
\end{itemize}
Observe-se que para qualquer $A \subset \R^n$, temos que 
$int \, A \cup \partial A \cup ext \, A = \R^n$ e $int \, A \cap \partial A \cap ext \, A = \emptyset$.\\
Um conjunto $A \in \R$ diz-se: \vspace{-0.8mm}
\begin{itemize}
\item \textbf{aberto} se $A= int \, A$ \vspace{-1mm}
\item \textbf{fechado} se $A= \overline{A}$ ($\R/A$ é aberto ou $\partial A \subset A$) \vspace{-0.8mm}
\item Um conjunto $A$ diz-se \textbf{limitado} se houver $x \in \R$ e $R \in \R^+$ tal que $A \subset B_R(x)$.
\item \textbf{compacto} se é fechado e limitado \vspace{-0.8mm}
\end{itemize}
A interseção/união de uma família de conjuntos abertos/fechados é também aberto/fechado.

\subsection{Sucessões}
Recorda-se que uma sucessão é essencialmente uma bijeção/correspondência entre um conjunto $\{ u_n: n \in \mathbb{N}^+\}$ e $\mathbb{N}^+$.
Seja $u_n$ uma sucessão de termos em $\R^n$. Observa-se que cada coordenada de $u_n$ descreve ela própria um sucessão de termos em $\R^n$. Assim, para cada $j \leq m$ damos o nome de \textbf{sucessões coordenadas} às sucessões $(u_{j_n})$ cujo termo de ordem $k$ corresponde à $j$-ésima coordenada de $u_k$.\\
Diz-se que uma sucessão $(u_n) \subset \R^n$ tende/converge para $u \in \R^n$ (e escreve-se $u_n \to u$) se e só se, para qualquer $\epsilon \in \R^+$ existe $p \in \mathbb{N}^+$ tal que $u_n \in B_\epsilon(u)$ para todo o $n>p$. É fácil de ver que esta definição é equivalente a verificar se a sucessão $d_n = || u_n - u ||$ é infinitesimal. Uma sucessão que convirja para $u \in \R^n$ diz-se \textbf{convergente}.\\
Note-se que as definições a cima enunciadas de convergência são pouco práticas. De facto, é bastante mais prático usar o seguinte facto:\\
Uma sucessão $(u_n)$ converge para $a = (a_1, a_2, \cdots , a_n) \in \R^n$ se e só se as sucessões coordenadas $u_{j_n}$ tendem para $a_j$ para todo o $j \in \{ 1,2, \cdots , n \}$. É então fácil verificar que o limite de uma sucessão em $\R^n$ é único (se existir).\\
Observe-se que qualquer sucessão de termos em $X \in \R^n$ tem limite na aderência de $X$. Então um conjunto é fechado se e só se qualquer sucessão de termos nesse conjunto tiver limite dentro do conjunto.\\
Diz-se ainda que uma sucessão é limitada se e só se o conjunto dos seus termos também o for. Tendo em conta os resultados a cima, é fácil concluir que uma sucessão é limitada se e só se as suas sucessões coordenadas também o forem. Verificam-se as seguintes propriedades:
\begin{itemize}
	\item Qualquer sucessão convergente é limitada.
	\item \textbf{Teorema de Bolzano-Weiestrass}: Qualquer sucessão limitada tem sub-sucessões convergentes.
\end{itemize}

\subsection{Continuidade}
Uma função $f: D \subset \R^n \to \R^m$ diz-se contínua num ponto $a \in \R^n$ se para qualquer bola de raio $\delta \in \R^+$ centrada em $f(a)$, existe uma bola de raio $\epsilon \in \R^+$ centrada em $a$ tal que 
$$x \in B_\epsilon(a) \, \cap \, D \Rightarrow f(x) \in B_\delta(f(a)) \quad (\forall \delta \in \R^+, \, \exists \epsilon \in \R^+ : ||x-a|| < \epsilon \vee x \in D \Rightarrow ||f(x)-f(a)|| < \delta)$$
Tal como em $\R$ (definição de Heine), podemos definir continuidade através de sucessões. Uma funçao $f : D \subset \R^n \to \R^m$ é contínua em $a \in D$ se e só se para qualquer sucessão $(u_n)$ de termos em $D$ convergente para $a$ se tem que $f(u_k) \to f(a)$.\\
Tal como nas sucessões, por vezes o estudo da continuidade de uma função torna-se mais simples se considerarmos as \textbf{funções coordenadas}. Seja uma função $f: D \subset \R^n \to \R^m$. Se considerarmos apenas o que $f$ faz à $k$-ésima coordenada dos objetos de $D$, obtemos uma função $f_k(x)$, de domínio em $\R$ a qual designamos de $k$-ésima função coordenada de $f$. Tal função $f$ será contínua num ponto $a \in D$ se e só se as $m$ funções coordenadas também o forem nas respetivas corrdenadas.\\
Propriedades de funções contínuas:
Se $f,g: \R^n \to \R^m$ forem contínuas em $a \in \R$ e $h: \R^m \to \R^l$ for contínua em $f(a) \in \R$, e $\alpha \in \R$ então:
\begin{itemize}
	\item $f \pm g$, $f \cdot g$, $||f||$, $\alpha f$, $f/g$ com $g(x) \neq 0$, são contínuas em $a$;
	\item $(h \circ f)$ é contínua em $a$;
\end{itemize}
Finalmente, introduzimos a noção de conexividade. Dois conjuntos $A,B \subset \R^n$ dizem-se \textbf{separados} se 
$$
A \cap \overline{B} = \overline{A} \cap B = \emptyset
$$
Um conjunto $C$ diz-se \textbf{conexo} se não houverem $A,B \subset C$ não-vazios tais que $A$ e $B$ são separados.\\
Teoremas sobre funções contínuas:
\begin{itemize}
	\item Uma função contínua transforma conjuntos compactos em conjuntos compactos;
	\item \textbf{Teorema de Weiestrass}: Uma função escalar contínua de domínio compacto em $\R^n$ tem máximo e mínimo;
	\item Uma função contínua transforma conjuntos conexos em conjuntos conexos;
	\item \textbf{Teorema do Valor Intermédio}: Seja $f : D \subset \R^n \to \R$ contínua de domínio conexo. Se $a,b \in f(D)$ com $b<a$ então $[a,b] \subset f(D)$.
\end{itemize}

\subsection{Limites}
Tal como em CDI-I, definimos o \textbf{prolongamento contínuo} de uma função $f: D \subset \R^n \to \R^m$ como a função contínua $\tilde{f}: D^* \subset \overline{D} \to \R^m$ tal que $\tilde{f}(x) = f(x)$ para $x \in D$ e $D^*$ corresponde ao conjunto dos pontos em $\overline{D}$ tais que $f$ é prolongável por continuidade nesses pontos.\\
Então, definimos o limite de $f$ em $a \in \R$ como o valor do prolongamento contínuo de $f$ nesse ponto.
$$
\lim_{x \to a} f(x) = \tilde{f}(x)
$$
O limite de $f$ só existe nos pontos prolongáveis por continuidade.\\
Equivalentemente temos que para uma função $f: D \subset \R^n \to \R^m$:
$$
\lim_{x \to a} f(x) = b
$$
se e só se
\begin{itemize}
	\item Para qualquer sucessão de termos em $D$ tal que $u_n \to a$ se verifica que $f(u_n) \to f(a)$;
	\item $\forall_{\delta \in \R^+}, \exists_{\epsilon \in \R^+}: x \in B_\epsilon(a) \cap D \Rightarrow f(x) \in B_\delta(b)$.
\end{itemize}
Note-se que para um limite existir num ponto $a$, este tem de ser igual em todas as curvas que passam por esse ponto. Nomeadamente, o limite de uma função em $a$ só pode existir se o limite existir e for igual segundo todas as retas por $a$ (note-se que o limite segundo uma reta é um limite em $\R$). A estes limites (segundo retas) dá-se o nome de \textbf{limites direcionais} segundo uma reta/vetor.
No entanto, e como é impossível verificar o limite de uma função segundo todas as curvas que passam por um ponto, é necessário um método para calcular um limite.\\
Para este propósito usamos o \textbf{método das funções enquadradas}: Sejam $f,g,h: \R^n \to \R$ definidas em $B_r(a)$ para $a \in \R^n, r \in \R^+$. Então:
$$
f(x) \geq g(x) \geq h(x) \quad \forall_{x \in B_r(a)} \Rightarrow \lim_{x \to a} f(x) \geq \lim_{x \to a} g(x) \geq \lim_{x \to a} h(x) 
$$
e nomeadamente, se $\lim_{x \to a} f(x) = \lim_{x \to a} h(x) = b$ temos que $\lim_{x \to a} g(x) = b$.

\section{Diferenciabilidade}
\subsection{A Derivada}
Vimos em CDI-I que, entre outras, uma possível definição de derivada de uma função $f$ num ponto $a$ ($f'(a)$) é tal que 
$$
f(x) = f(a) + f'(a)(x-a) + r(x)
$$
em que $r(x)$ é uma função resto tal que $\frac{r(x)}{x-a} \to 0$ quando $x \to a$.\\
Note-se que a função $g(x) = f(a) + f'(a)(x-a)$ é uma função afim. De facto, esta é a melhor aproximação afim da função $f$.\\ 
Definimos então a derivada de uma função $f$ num ponto $a$ como a transformação linear $Df(a)$ que melhor aproxima $f$ na vizinhança de $a$. Note-se que $f$ vai então ser diferenciável se e só se esta transformação linear existir. Nesse caso, temos que:
$$
f(x) = f(a) + Df(a)(x-a) + r(x)
$$
Note-se que isto significa que a função $g(x) = f(a) + Df(a)(x-a)$ será o hiper-plano tangente á função $f$ no ponto $a$ (nomeadamente, para funções de domínio em $\R$, o hiper-plano é uma reta - a reta tangente).\\
Como qualquer transformação linear, $Df(a)$ pode ser representado por uma matriz. Se $f: \R^n \to \R^m$, $Df(a)$ vai ser representado por uma matriz $m \times n$, a qual se dá o nome de \textbf{matriz Jacobiana}.\\
Para construir a matriz Jacobiana, vemos o que esta faz aos vetores canónicos. Considere-se então $e_k$, o $k$-ésimo vetor canónico de $\R^n$. Vemos que:
$$
f(a + te_k) = f(a) + Df(a)(te_k) + r(te_k) \Leftrightarrow
$$
$$
Df(a)e_k = \lim_{t \to 0} \frac{f(a + te_k)-f(a)}{t}
$$
De forma que a matriz Jacobiana será constituída por $n$ vetores coluna dados pelo limite a cima, avaliado para cada vetor canónico. A este limite dá-se o nome de \textbf{derivada parcial} de $f$ em $a$, em ordem à variável $x_k$. Observando que o limite em cima origina um vetor com $m$ coordenadas, correspondentes aos limites
$$
\lim_{t \to 0} \frac{f_j(a + te_k)-f_j(a)}{t}
$$
em que $f_j$ representa uma das $m$ funções coordenadas de $f$, obtemos então a matriz:\\
\begin{center}
$Df(a) = $
$\begin{bmatrix}
	\frac{\partial f_1}{\partial x_1}(a) & \frac{\partial f_1}{\partial x_2}(a) & \cdots & 	\frac{\partial f_1}{\partial x_n}(a) \\
	\\
	\frac{\partial f_2}{\partial x_1}(a) & \frac{\partial f_2}{\partial x_2}(a) & \cdots & 	\frac{\partial f_2}{\partial x_n}(a) \\
	\\
	\cdots & \cdots & \cdots & \cdots \\
	\\
	\frac{\partial f_m}{\partial x_1}(a) & \frac{\partial f_m}{\partial x_2}(a) & \cdots & 	\frac{\partial f_m}{\partial x_n}(a) \\
\end{bmatrix}$
\end{center}
A noção de derivada parcial pode ser generalizada para vetores que não os canónicos. Define-se \textbf{derivada direcional} segundo um vetor $v$ (caso exista) como:
$$
\frac{\partial f}{\partial v}(a) = \frac{\partial}{\partial t} f(a+tv) \Big|_{t=0} = \lim_{t \to 0} \frac{f(a+tv)-f(a)}{t}
$$
A derivada segundo qualquer vetor $v$ pode no entanto ser obtida por meio da matriz Jacobiana. Para uma função $f: D \subset \R^n \to \R^m$ diferenciável em $a$, temos que, para qualquer $v \in \R^n$:
$$
\frac{\partial f}{\partial v}(a) = Df(a) \cdot v
$$
($\frac{\partial f}{\partial v}(a)$ é a imagem de $v$ por $Df(a)$).\\
Então,
$$
\frac{\partial f}{\partial v}(a) = Df(a)\cdot v = \sum_{j=1}^n v_j \cdot Df(a)e_j = \sum_{j=1}^n v_j \frac{\partial f}{\partial x_j} (a)
$$
\subsection{Propriedades da derivada}
\begin{itemize}
	\item $f$ é diferenciável em $a$ se e só se todas as suas funções coordenadas o forem;
	\item Qualquer função diferenciável é contínua;
	\item A existência de todas as derivadas parciais num ponto não é condição suficiente para a existência de derivada nesse ponto; 
	\item A existência e continuidade de todas as derivadas num ponto é condição suficiente para a existência de derivada nesse ponto. Ou seja, qualquer função de derivada contínua é diferenciável.
	\item A combinação linear de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D(\alpha f+\beta g)(a)=\alpha Df(a)+\beta Dg(a)$$
	\item O produto de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D(fg)(a)=Df(a)g(a)+f(a)Dg(a)$$
	\item O quociente de funções $f$ e $g$ diferenciáveis num ponto $a$ é diferenciável e é dada por $$ D\left(\frac{f}{g} \right)(a)=\frac{Df(a)g(a)-f(a)Dg(a)}{g(a)^2} $$
	\item Sejam $D \subset \R^n$ e $E \subset \R^m$ abertos tal que $f: D \to \R^m$ e $g: E \to \R^k$ são diferenciáveis e $f(D) \subset E$. Então $g \circ f: D \to \R^k$ é diferenciável e $$ D(g \circ f)(a) = Dg(f(a)) \cdot Df(a) $$
\end{itemize}
Atentemos nesta última propriedade. A derivada da composição de funções é dada por um produto matricial. Esta propriedade dá-nos uma forma de calcular derivadas parciais das funções coordenadas da função composta em função das derivadas parciais das funções que a compôem. Dadas funções $f: D \to \R^m$ e $g: E \to \R^k$ com $D \subset \R^n$ e $E \subset \R^m$ abertos e $f(D) \subset E$, temos que
$$
\frac{\partial (g \circ f)_i }{\partial x_j}(x) = \left[ D(g \circ f)(x) \right]_{i,j} = \sum_{l=1}^m \left[ Dg(f(x)) \right]_{i,l} \left[ Df(x) \right]_{l,j} = \sum_{l=1}^m \frac{\partial g_i}{\partial y_l}(f(x)) \cdot \frac{\partial f_l}{\partial x_j}(x)
$$
Esta regra é conhecida por \textbf{regra da cadeia}.\\

\subsection{Gradiente}
Concentrando-nos agora em campos escalares, vemos que para uma função $f: D \subset \R^n \to \R$, a matriz jacobiana tem apenas uma linha. Desta forma, ela pode ser representada na forma vetorial. Ao vetor
$$
\nabla f(a) = \left( \frac{\partial f_1}{\partial x_1}(a) \quad \frac{\partial f_1}{\partial x_2}(a) \quad \cdots \quad \frac{\partial f_1}{\partial x_n}(a) \right)
$$
dá-se o nome de \textbf{gradiente} de $f$ em $a$. Desta forma, o gradiente de uma função escalar é um campo vetorial $\nabla f: D \subset \R^n \to \R^n$ que a cada ponto $x \in D$ faz corresponder o vetor $\nabla f(x)$.\\
Neste caso, vemos que a derivada duma função escalar $f$ num ponto $a$ segundo um vetor $v$ é dada pelo produto vetorial:
$$
\frac{\partial f}{\partial v}(a) = Df(a) \cdot v = \nabla f(a) \cdot v = || \nabla f(a) || \cdot ||v|| \cdot \cos \theta
$$
em que $\theta$ é o ângulo entre o vetor $v$ e o vetor $\nabla f(a)$. Como este valor é máximo quando $\theta = 0$, temos que o vetor gradiente dá-nos a direção e sentido de crescimento máximo de $f$ (em $a$).\\
Observe-se ainda que se $v \perp \nabla f(a)$ então a derivada de $f$ em $a$ segundo $v$ é nula.\\
Note-se que com os vetores linha da matriz jacobiana de uma função $f: D \subset \R^n \to \R^m$ correspondem aos gradientes das funções coordenadas de $f$:
\begin{center}$
\renewcommand*{\arraystretch}{1.2}
Df(a) =
\begin{bmatrix}
\nabla f_1(a) \\
\nabla f_2(a) \\
\cdots \\
\nabla f_n(a) \\
\end{bmatrix}$
\end{center}

\subsection{Linhas, Conjuntos de Nível e Tangentes}
Dá-se o nome de \textbf{caminho} ou \textbf{trajetória} a uma função contínua $\gamma: I \to \R^n$ em que $I \subset \R$ é um intervalo. Ao conjunto de chegada de $\gamma$ dá-se o nome de \textbf{linha}.\\
Define-se um \textbf{vetor tangente} a um caminho $\gamma$ de classe $C^1$como o vetor dado pelo limite
$$
\gamma '(t) = \lim_{h \to 0} \frac{\gamma(t+h)-\gamma(t)}{h}
$$
Note-se que isto é apenas um reaproveitamento da ideia de aproximar a reta tangente por secantes em pontos cada vez menos distantes na linha.\\
Se $\Gamma$ for a linha definida por $\gamma$, e $t$ for um ponto no domínio de $\gamma$, a reta tangente a $\Gamma$ pelo ponto $\gamma (t)$ é a reta de equação $x = \gamma(t) + \lambda \gamma '(t)$, para $\lambda \in \R$. \\
Definimos agora um \textbf{conjunto de nível} de $f: D \subset \R^n \to \R$ como um conjunto da forma 
$$
S_c(f) = \{ x \in D: f(x)=c \}
$$
Seja $\gamma: I \subset \R \to \R^n$ um caminho cuja linha $\Gamma$ está contida num conjunto de nível $S_\alpha (f)$ e seja $t, t_0 \in I$ com $t \in V_\epsilon(t_0)$ ($\epsilon \in \R^+$). Como $\Gamma \subset S_\alpha(f)$, temos que $(f \circ \gamma) (t_0) = \alpha$. Então:
$$
\frac{\partial}{\partial t} (f \circ \gamma)(t_0) = 0 \Leftrightarrow \nabla f(\gamma(t_0)) \cdot \gamma'(t_0) = 0 \Leftrightarrow \nabla f(\gamma (t)) \perp \gamma'(t)
$$
Então, o gradiente de uma função num ponto de um conjunto de nível (dessa função) é sempre ortogonal a esse conjunto. Diz-se, para tais pontos $p$ na linha $\Gamma \subset S_\alpha (f)$ que o vetor $\nabla f(p)$ é \textbf{normal} a $\Gamma$ em $p$.\\ 
Note-se que esta observação permite-nos definir equações para planos. Seja $G_f$ o gráfico de uma função escalar $f: \R^{n-1} \to \R$, ou seja, $G_f = \{ (x_1, x_2, \cdots, x_n) \in \R^n : x_n = f(x_1, x_2, \cdots , x_{n-1}) \}$. Se considerarmos a função $F: \R^n \to \R$ definida por $F(x) = x_n - f(x_1, x_2, \cdots , x_{n-1})$, temos que $G_f = S_0(F)$, de forma que o plano tangente a $G_f$ por um ponto $p \in D_f$ tem vetor normal 
$$
\nabla F(p) = \left( -\frac{\partial f}{\partial x_1}(p), -\frac{\partial f}{\partial x_2}(p), \cdots , -\frac{\partial f}{\partial x_{n-1}}(p), 1 \right)  
$$
Conclui-se então que o plano tangente a $f$ por um ponto $f(p)$ é dada por
$$
x_n = f(p) + \frac{\partial f}{\partial x_1}(p)(x_1-p_1) + \frac{\partial f}{\partial x_2}(p)(x_2-p_2) + \cdots + \frac{\partial f}{\partial x_{n-1}}(p)(x_{n-1}-p_{n-1}) 
$$

\subsection{Derivadas de Ordem Superior}
Para qualquer $D \subset \R^n$ aberto e um campo escalar $f \in C^1(D)$, temos que as derivadas parciais $\frac{\partial f}{\partial x_k}$ ($k \in \{ 1, 2, \cdots, n \}$) são também campos escalares definidos em $D$. Se estas funções forem também elas diferenciáveis, podemos definir as \textbf{derivadas de segunda ordem} de $f$:
$$
\frac{\partial}{\partial x_j} \left( \frac{\partial f}{\partial x_i} \right) = \frac{\partial ^2 f}{\partial x_j x_i}
$$
Mais genericamente, para indices $i_1, i_2, \cdots , i_k \in \{ 1, 2, \cdots , n \}$, designamos por derivada de ordem $k$ à função
$$
\frac{\partial ^k f}{\partial x_{i_1}x_{i_2} \cdots x_{i_k}}
$$
Se esta função estiver definida e for contínua em $D$, dizemos que $f$ é de classe $C^k$ em D, e escrevemos $f \in C^k(D)$. Se $f$ for de classe $C^k$ em $D$ para todo o $k \in \mathbb{N}$, então escreve-se que $f \in C ^\infty (D)$.\\

\textbf{Teorema de Schwartz}: Seja $f: D \subset \R^n \to \R^m$ de classe $C^2$ em $D$ aberto. Então
$$
\frac{\partial}{\partial x_j} \left( \frac{\partial f}{\partial x_i} \right) = \frac{\partial}{\partial x_i} \left( \frac{\partial f}{\partial x_j} \right) = \frac{\partial ^2 f}{\partial x_j x_i}
$$
Mais genericamente, se $\{ i_1, i_2, \cdots , i_k \}$ for um conjunto de índices e $\sigma$ for uma permutação desse conjunto, temos que
$$
\frac{\partial ^k f}{\partial x_{i_1} \partial x_{i_2} \cdots \partial x_{i_k}} = \frac{\partial ^k f}{\partial x_{\sigma(i_1)} \partial x_{\sigma(i_2)} \cdots \partial x_{\sigma(i_k)}}
$$
A notação mais frequente para escrever este tipo de derivadas é então
$$
\frac{\partial ^N f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \cdots \partial x_n ^{\alpha_n}}
$$
em que $\alpha_i$ representa o número de vezes que se diferencia em ordem à variável $x_i$ e $N = \sum_{i=0}^n \alpha_i$.

\subsection{Extremos e Teorema de Taylor}
Tal como anteriormente, para estudar o extremo de uma função num ponto, vamos considerar o que acontece a essa função de acordo com certas retas (analisar uma função segundo uma reta permite-nos transformar o estudo de uma função em $\R^n$ no estudo de uma função em $\R$).\\
Considere-se então a função $\gamma: \R \to \R^n$ definida por $\gamma (t) = a + th$. Desta forma, temos que $g(t) = f(\gamma(t))$ consiste nos valores que $f$ toma sobre a reta por $a$ de vetor diretor $h$. Temos que $f$ vai ter um extremo em $a$ se e só se $g$ tiver um extremo em $t=0$, pelo que $f$ tem um extremo se e só se
$$
g'(0) = (f \circ \gamma )' (0) = \nabla f(\gamma (0)) \cdot \gamma'(0) = \nabla f(a) h
$$
for nulo para qualquer vetor $h$. Conclui-se que $f$ tem um extremo em $a$ no interior do seu domínio se e só se:
$$
\nabla f(a)=0
$$
Aos pontos que satisfazem esta propriedade dá-se o nome de \textbf{pontos críticos} de $f$. Note-se que nem todos os pontos críticos são extremos da função. Aos pontos críticos de $f$ que não são extremos dessa função dá-se o nome de \textbf{pontos de sela}. Pode-se no entanto dizer que o conjunto dos extremos no interior do domínio de uma função está contido no conjunto dos pontos críticos dessa função.\\
Torna-se então necessário arranjar um método de distinguir os extremos dos pontos de sela de uma função. Para funções em $\R$ isto podia ser feito através do Teorema de Taylor. Voltamos então a restringir a análise da função aos valores que esta toma segundo uma reta, ou seja, voltamos a considerar a função $\gamma: \R \to \R^n$ definida por $\gamma (t) = a + th$, de forma que $f$ tem polinómio de Taylor segundo a reta definida por $h$:
$$
f(a+th) = f(a) + \frac{\partial f}{\partial h}(a)t + \frac{1}{2!}\frac{\partial ^2 f}{\partial h^2}(a) t^2 + ... + \frac{1}{n!} \frac{\partial ^n f}{\partial h^n}(a)t^n + r_{n+1}(t)
$$
sendo que
$$
\frac{\partial f}{\partial h}(a) = \sum_{j=1}^n \frac{\partial f}{\partial x_j}(a) h_j = \nabla f(a) h  \quad \quad \quad \quad 
\frac{\partial ^2 f}{\partial h^2}(a) = \sum_{k=1}^n \sum_{j=1}^n \frac{\partial ^2 f}{\partial x_j x_k} (a) h_j h_k 
$$
$$
\frac{\partial ^3 f}{\partial h^3}(a) = \sum_{k,i,j =1}^n \frac{\partial ^3 f}{\partial x_i x_j x_k} (a) h_i h_j h_k
$$
e por aí em diante.\\
Note-se que a segunda derivada em $a$ pode ser escrita como um produto matricial $h^T \cdot D^2 f(a) \cdot h$ em que:
$$
D^2 f(a) = 
\renewcommand*{\arraystretch}{1.8}
\begin{bmatrix}
\frac{\partial ^2 f}{\partial x_1 ^2} (a) && \frac{\partial ^2 f}{\partial x_2 x_1} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n x_1} (a) \\
\frac{\partial ^2 f}{\partial x_1 x_2} (a) && \frac{\partial ^2 f}{\partial x_2^2} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n x_2} (a) \\
\cdots && \cdots && \cdots && \cdots \\
\frac{\partial ^2 f}{\partial x_1 x_n} (a) && \frac{\partial ^2 f}{\partial x_2 x_n} (a) && \cdots && \frac{\partial ^2 f}{\partial x_n ^2} (a)
\end{bmatrix}
$$
A esta matriz dá-se o nome de \textbf{matriz Hessiana} de $f$ no ponto $a$. Esta representação da segunda derivada permite-nos usar conhecimento de Álgebra Linear para estudar os pontos críticos da função. Relembra-se que uma matriz se diz:
\begin{itemize}
	\item Definida positiva/negativa se todos os seus valores próprios forem, respetivamente, positivos/negativos;
	\item Semi-definida positiva/negativa se todos os seus valores próprios forem, respetivamente, não-negativos/não-positivos;
	\item Indefinida se tiver valores próprios positivos e negativos;
\end{itemize}
Então, para um ponto crítico de $f$, temos que:
$$
\frac{f(a+th)-f(a)}{t^2} = \frac{1}{2!}\frac{\partial ^2 f}{\partial h^2}(a) + \frac{r_3(t)}{t^2} \Rightarrow \lim_{t \to 0} \frac{f(a+th)-f(a)}{t^2} = \frac{1}{2!} \frac{\partial ^2 f}{\partial h^2}
$$
pelo que $f(a+h)-f(a)$ tem o mesmo sinal que a segunda derivada de $f$. Como, segundo o teorema de Schwartz, a matriz Hessiana é sempre simétrica, e temos que a matriz Hessiana é diagonalizável. Então, há valor próprio $\lambda$ e vetor próprio $h$ associado a $\lambda$ tais que:
$$
\frac{\partial ^2 f}{\partial h^2}(a) = h^T \cdot D^2 (a) \cdot h = h^T \cdot \lambda h = \lambda ||h||^2
$$
Pelo que, o sinal de $f(a+h)-f(a)$ é dado pelo sinal dos valores próprios da matriz Hessiana de $f$. Concluímos então que para $a$ no interior do domínio de um campo escalar $f$:
\begin{itemize}
	\item Se a Hessiana de $f$ em $a$ for definida positiva, então $a$ é um mínimo local;
	\item Se a Hessiana de $f$ em $a$ for definida negativa, então $a$ é um máximo local;
	\item Se a Hessiana de $f$ em $a$ for indefinida, então $a$ é um ponto em sela;
	\item Se $a$ é um mínimo local então a Hessiana de $f$ em $a$ é semi-definida positiva;
	\item Se $a$ é um máximo local então a Hessiana de $f$ em $a$ é semi-definida negativa;
\end{itemize}
Note-se que esta abordagem pode por vezes não funcionar. Nestes casos, é necessário estudar diretamente o valor de $f$ numa bola à volta de $a$.

\section{Variedades}
\subsection{Teorema da Função Inversa}
Seja $f:A \subset \R^n \to \R^n$ de classe $C^1$ no aberto $A$ e seja $a \in A$. Se $|Df(a)| \neq 0$, então $f$ é invertível numa bola centrada em $a$ ($B_r(a)$) e a sua inversa é também de classe $C^1$ e tem derivada dada por
$$
Df^{-1}(y) = \left( Df(x) \right)^{-1}
$$
para todo o $y \in B_r(a)$ e $x \in \R^n$ tal que $f(x) = y$.\\
Notas:
\begin{itemize}
    \item Este teorema dá-nos apenas que a função será invertível na vizinhança, não nos permite tirar nenhum resultado sobre intervalos (mesmo que a função seja invertível em todos os pontos);
    \item Se $|Df(a)|=0$, o teorema não tira conclusões nenhumas (a função pode ser invertível numa vizinhança de $a$ na mesma - pensar nas funções $x^2$ e $x^3$, naorigem).
\end{itemize}

\subsection{Teorema da Função Implícita}
O gráfico de uma função escalar $f: \R^n \to \R$ é o conjunto
$$ G(f) = \{(x,y) \in \R^n \times \R: y = f(x) \} \subset \R^{n+1} $$
alternativamente, podemos definir este conjunto como $G(f) = \{(x,y) \in \R^{n+1}: F(x,y) = 0 \}$, em que $F: \R^{n+1} \to \R$ é definida por $F(x,y) = y - f(x)$, pelo que $G(f)$ é o conjunto de nível 0 da função $F$.

Será, no entanto, que podemos tirar conclusões no sentido contrário? Isto é, dado uma conjunto de nível de uma função $F(x,y)$, será que há uma função $f: \R^n \to \R$ tal que $y = f(x)$? Se a resposta for afirmativa, dizemos que $f$ é definida \textbf{implicitamente} por $F$, ou mais especificamente, pela equação $F(x,y) = 0$.

A resposta a tal questão é dada pelo \textbf{Teorema da Função Implícita}\\
Seja $F: A \subset \R^n \to \R^m$, com $m<n$ uma função de classe $C^1$ definida num aberto $A$. Seja $(a,b) \in \R^n$ tal que $a \in \R^{n-m}$ e 
$$
F(a,b) = 0; \quad \det D_yF(a,b) \neq 0
$$
Então, existe uma função $f: B_\epsilon(a) \to \R^m$ de classe $C^1$ tal que, nessa bola em torno de $(a,b)$ se tem que 
$$
F(x,y) = 0 \Leftrightarrow y = f(x)
$$

Nesse caso, podemos conclur que $F(x, f(x)) = 0$ e, derivando, que $D_xF(a,b) + D_yF(a,b)Df(a) = 0$, o que nos dá
$$ Df(a) = - (D_yF(a,b))^{-1} D_xF(a,b) $$

Nomeadamente, temos que:
\begin{itemize}
    \item Para uma função $F:\R^2 \to \R$ de classe $C^1$ e $(a,b) \subset \R^2$ tal que $F(a,b)=0$, existe uma função $f: \R \to \R$ definida implicitamente por $F$ à volta de $(a,b)$, se e só se $\frac{\partial F}{\partial y} \neq 0$. Se esse for o caso, temos que:
$$
f'(a) = -\frac{\frac{\partial F}{\partial x}(a,b)}{\frac{\partial F}{\partial y}(a,b)}
$$
    \item Para uma função $F:\R^3 \to \R$ de classe $C^1$ e $(a,b,c) \subset \R^3$ tal que $F(a,b,c)=0$, existe uma função $f: \R^2 \to \R$ definida implicitamente por $F$ à volta de $(a,b,c)$, se e só se $\frac{\partial F}{\partial z} \neq 0$. Se esse for o caso, temos que:
$$
\frac{\partial f}{\partial x}(a,b) = -\frac{\frac{\partial F}{\partial x}(a,b,c)}{\frac{\partial F}{\partial z}(a,b,c)} \quad \text{ e } 
\quad \frac{\partial f}{\partial y}(a,b) = -\frac{\frac{\partial F}{\partial x}(a,b,c)}{\frac{\partial F}{\partial z}(a,b,c)}
$$
    \item Para uma função $F:\R^3 \to \R^2$ de classe $C^1$ definida por duas funções coordenada $F_1$ e $F_2$, e $(a,b,c) \subset \R^3$ tal que $F(a,b,c)=(0,0)$, existe uma função $f: \R \to \R^2$ definida implicitamente por $F$ à volta de $(a,b,c)$, se e só se $\det D_{y,z}F(a,b,c) \neq 0$. Se esse for o caso, temos que:
$$
f'(a) = \begin{bmatrix} f_1(a) \\ f_2(a) \end{bmatrix} 
= - \begin{bmatrix} 
\frac{\partial F_1}{\partial y}(a,b,c) & \frac{\partial F_1}{\partial z}(a,b,c) \\
\frac{\partial F_2}{\partial y}(a,b,c) & \frac{\partial F_2}{\partial z}(a,b,c) 
\end{bmatrix}^{-1} \begin{bmatrix} \frac{\partial F_1}{\partial x}(a,b,c) \\
\frac{\partial F_2}{\partial x}(a,b,c) \end{bmatrix}
$$
\end{itemize}

\subsection{Variedades}
Uma \textbf{variedade} é, de forma vaga, a definição matemática que usamos para descrever uma superfície em $\R^n$ em que o teorema da função implícita seja aplicável. 

Define-se $M \subset \R^n$ como uma variedade de dimensão $n-m$ se, para qualquer ponto $a \in M$, existe uma bola $B = B_\epsilon(a)$ centrada em $a$, tal que o conjunto $M \cap B$ pode ser descrito de uma das três seguintes maneiras:
\begin{itemize}
    \item Como conjunto de nível zero de uma função $F: \R^n \to \R^m$ ($m<n$) de classe $C^1$, definida num aberto tal que a matriz derivada $DF(x)$ tem característica $m$ para qualquer $x \in M \cap B$:
$$ M \cap B = \{ x \in \R^n: F(x) = 0 \} $$
note-se que a condição da característica é necessária para se poder aplicar o Teorema da Função Implícita (garante a invertibilidade da matriz das variáveis dependentes);
    \item Como gráfico de uma função $f: A \subset \R^{n-m} \to \R^m$ de classe $C^1$, definida num aberto:
$$ M \cap B = \{ (u,v) \in \R^{n-m} \times \R^m: v=f(u), u \in A \} $$
    \item Como a imagem de uma função $g: T \subset \R^{n-m} \to \R^n$ injetiva de classe $C^1$ em $T$ aberto definida tal que a matriz derivada $Dg(t)$ tem característica $n-m$ para qualquer $t \in T$:
$$ M \cap B = \{ g(t), t \in T \} = g(T) $$
à função $g$ dá-se o nome de \textbf{parametrização} de $M$ à volta de $a$.
\end{itemize}

\subsection{Espaços tagentes e normais a variedades}
Definimos agora:
\begin{itemize}
    \item Um vetor tangente a uma variedade como a um vetor que é tangente a uma linha que pertença a tal variedade;
    \item \textbf{Espaço tangente} a uma variedade num ponto como o espaço constituído por todos os vetores tangentes à variedade nesse ponto. Este espaço tem a mesma dimensão que a variedade e designa-se por $T_aM$;
    \item \textbf{Espaço normal} a uma variedade como o espaço ortogonal ao espaço tangente da variedade. Designado por $(T_aM)^\perp$.
\end{itemize}
Conjugando a primeira e a terceira definição de variedade observamos que $F(g(t))=0$ para todo o $t$ no domínio de $g$. Derivando, obtemos que
$$ DF(g(t)) \cdot Dg(t) = 0 $$
pelo que as colunas da matriz $Dg(t)$ são ortogonais às linhas da matriz $DF(g(t))$. 

Como as colunas de $Dg(t)$ são os vetores tangentes a $M$ segundo as direções dos eixos coordenados de $\R^{n-m}$, temos que estas colunas geram o espaço tangente a $M$. Consequentemente, de acordo com a igualdade a cima, temos que as linhas da matriz $DF(a)$ geram o espaço normal a $M$ em $a$.

Note-se então que, o método para estudar o espaço tangente/normal de uma variedade $M$ depende da forma como esta está definida:
\begin{itemize}
	\item Se $M$ for definido por o conjunto de nível de uma função $F$, o espaço normal num ponto $a$ é definido pela derivada $DF(a)$, e o espaço tangente pode ser calculado pela relação de ortogonalidade;
	\item Se $M$ for definido por uma parametrização $g$, obtemos o espaço tangente em $a$ pela derivada $Dg(a)$, e o espaço normal pela condição de ortogonalidade.
\end{itemize}

\subsection{Extremos Condicionados e Multiplicadores de Lagrange}
Admita-se que queremos encontrar os extremos de uma função $f: \R^n \to \R$ de classe $C^1$ restringida a uma variedade $M = \{x \in \R^n : F(x) = 0 \}$ para alguma função $F: \R^n \to \R^m$ também de classe $C^1$.\\
Seja $\gamma: \R \to \R^n$ um caminho que define uma linha $\Gamma \subset M$ tal que $\gamma(0) = a$ para algum ponto $a \in M$. Então, temos que $f(a)$ ser um extremo de $f$ em $M$ equivale a $a$ ser um extremo de $f \circ \gamma: \R \to \R$ (para qualquer caminho $\gamma$):
$$ \frac{\partial}{\partial t} f(\gamma(0)) = 0 \Leftrightarrow 
   \nabla f(a) \cdot \gamma'(0) = 0 $$
pelo que $\nabla f(a)$ pertence ao espaço normal de $M$ em $a$. Aos pontos que satisfazem a propriedade a cima dá-se o nome de \textbf{pontos críticos} de $f$ em $M$. Temos então que qualquer extremo de $f$ em $M$ será também um ponto crítico de $f$ em $M$ (note-se que, no entanto, nem todos os pontos críticos têm de ser extremos). Como este espaço é gerado pelos vetores $\nabla F_1(a)$, $\nabla F_2(a)$, ..., $\nabla F_m(a)$, temos que, os extremos de $f$ em $M$ são os pontos $x$ tais que:
$$ \begin{cases}
\nabla \left( f - \lambda_1 F_1 - \lambda_2 F_2 - \cdots - \lambda_m F_m \right) (x) = 0 \\
F(x) = 0
\end{cases} $$
para escalares $\lambda_i \in \R$.

\section{Integrabilidade}

\subsection{O Integral}
Relembra-se do Cálculo I que a integração teve como motivação o cálculo da área de baixo de funções. Isto foi alcançado definindo estruturas "elementares" para as quais este problema era trivial (funções constantes em intervalos), e aproximar todoso os outros casos por estruturas desse tipo. Tal como feito anteriormente nesta disciplina, vamos tentar reduzir o caso multidimensional ao caso unidimensional, já estudado. Para isso, começamos então de definir intervalos em $\R^n$:\\
Um conjunto $I \subset \R^n$ diz-se um \textbf{intervalo} se $I = I_1 \times I_2 \times \cdots I_n$ onde cada $I_j \subset \R$ é um intervalo em $\R$.\\
Observa-se que $I$ será aberto, fechado ou limitado se e só se todas as suas arestas $I_1, \cdots, I_n$ forem, respetivamente, abertas, fechadas ou limitado.
Note-se que um intervalo limitado em $\R^2$/$\R^3$ é um retângulo/paralelipipedo alinhado com os eixos coordenados. É então intuitivo definir a área de um intervalo da seguinte forma:\\
Se $I = I_1 \times I_2 \times \cdots \times I_n$ é tal que $s_i = \sup(I_i)$ e $i_i = \inf(I_i)$ existem para todo o $i \in \{1,2,\cdots n\}$, então o \textbf{volume} (n-dimensional) de $I$ é dado por
$$
V_n(I) = \prod_{i=1}^n (s_i-i_i)
$$
note-se que para esta definição é irrelevante se os intervalos em $\R$ são abertos ou fechados.\\
Agora que já temos as nossas estruturas elementares, estamos prontos para aproximar os restantes casos:\\
Relembre-se de CDI-I que uma partição de um intervalo $I$ é um conjunto de pontos $P(I) = \{ x_0, x_1, \cdots, x_k \}$ tal que $x_0 = \inf(I)$ e $x_n = \sup(I)$. A cada partição associa-se a decomposição $I = \bigcap_{i=0}^{k-1} [a_i, a_{i+1}]$.\\
Generaliza-se então este conceito para $\R^n$ considerando uma \textbf{partição} de um intervalo limitado $I = I_1 \times \cdots I_n \subset \R^n$ como o produto cartesiano $P(I) = P(I_1) \times P(I_2) \times \cdots \times P(I_n)$. A estas partições também estará associada uma \textbf{decomposição} de $I$, dada pelo produto cartesiano dos intervalos da decomposição de cada "aresta" de $I$. Assim, temos um mecanismo para aproximar área de uma função, tal como em cálculo I:\\
Dada uma partição $P(I)$ de um intervalo limitado $I \subset \R^n$, o conjunto $D_P$ dos intervalos da decomposição associada a $P$ e um campo escalar limitado $f: \R^n \to \R$, definimos então a soma inferior ($s_P(f)$) e soma superior ($S_P(f)$) de $f$ relativa a $P$ como (respetivamente):
$$
s_P(f) = \sum_{X \in D_P} \inf(f|_X) \cdot V_n(X)
$$
$$
S_P(f) = \sum_{X \in D_P} \sup(f|_X) \cdot V_n(X)
$$
De forma semelhante a CDI-I, podemos definir partições mais finas e sobrepostas para fundamentar que os seguintes valores existem:
$$
\underline{\int_I} f = \sup \{ s_p(f): \forall \, P(I) \}
$$
$$
\overline{\int_I} f = \inf \{ S_p(f): \forall \, P(I) \}
$$
Definimos então \textbf{integrabilidade à Riemann} da seguinte forma:\\
Um campo escalar $f: I \subset \R^n$ diz-se integrável à Riemann se e só se $\overline{\int_I} f = \underline{\int_I} f$. Neste caso dá-se o nome de \textbf{integral} de $f$ em $I$ ao valor:
$$
\int_I f = \overline{\int_I} f = \underline{\int_I} f
$$

\subsection{Propriedades do Integral e Funções Integráveis}
Tal como em CDI-I, é fácil deduzir a partir desta definição as seguintes propriedades, para quaisquer campos escalares integráveis $f$ e $g$ sobre $I$:
\begin{itemize}
	\item $\int_I (af+bg) = a\int_I f + b \int_I g$;
	\item $f(x) \geq g(x) _{\forall x \in I} \Rightarrow \int_I f \geq \int_I g$.
	\item $\big| \int_I f \big| \leq \int_I |f|$.
\end{itemize}
Tentemos então agora responder à pergunta "Que funções são integráveis?". Começamos com a seguinte definição:\\
Define-se $A \in \R^n$ como um \textbf{conjunto de conteúdo nulo} se, dado $\epsilon >0$, existir uma coleção finita de intervalos $\{ I_k \}_{i=1}^N$ tal que:
$$
A \subset \bigcap_{k=1}^N I_k \quad \wedge \quad \sum_{k=1}^N vol(I_k) < \epsilon
$$
Temos que o gráfico de um campo escalar contínuo definido num intervalo compacto em $\R^n$ tem conteúdo nulo em $\R^{n+1}$.\\
É também fácil de concluir que a união finita de conjuntos de conteúdo nulo é também um conjunto de conteúdo nulo.\\
Chegamos então à seguinte condição para integrabilidade:\\
Qualquer função $f: I \subset \R^n \to \R$ contínua exceto num conjunto de conteúdo nulo é integrável em I.\\
A noção de conteúdo nulo pode ser generalizada para a noção de \textbf{medida nula}, se considerarmos uma coleção de intervalos contável e não apenas finita. Esta noção dá-nos não uma condição suficiente para integrabilidade, mas uma condição necessária e suficiente. Ou seja, uma função será integrável num intervalo se e só se for contínua exceto num conjunto de conteúdo nulo, nesse intervalo.\\ 

\subsection{Teorema de Fubini e Volumes}
Visto quais são as funções integráveis, falta-nos saber como integrar uma função. Para isso, servimo-nos do \textbf{Teorema de Fubini}:\\
Sejam $A \subset \R^n$ e $B \subset \R^m$ intervalos compactos, e seja $f$ um campo escalar limitado e integrável no intervalo $A \times B \subset \R^{n+m}$. Se, para cada $x \in A$, a função $y \to f(x,y)$ é integrável e a função $x \to \int_B f(x,y) \, dy$ é integrável em $A$, então
$$
\int_{A \times B} f(x,y) \, dx \, dy = \int_A \left( \int_B f(x,y) \, dy \right) \, dx = \int_B \left( \int_A f(x,y) \, dx \right) \, dy
$$
Ou seja, na prática, a integração de uma função em $n$ variáveis pode ser feita através de $n$ integrações em uma variável, fixando as restantes variáveis nesse processo. Aos intgerais desta forma dá-se o nome de \textbf{integrais iterados}.\\
Este teorema permite-nos calcular o volume de diversos sólidos. Para isto usamos a \textbf{função caraterística}. Define-se função característica de um conjunto $D \subset \R^n$ como a função $\chi_D: I \to \R$ tal que $D \subset I$ e:
$$
\chi _D(x) = 
\begin{cases}
1, \text{ se } x \in D \\
0, \text{ se } x \in I/D
\end{cases}
$$
Se esta função for integrável podemos então definir o $n$-volume do conjunto $D$ como:
$$
vol_n(D) = \int_I \chi _D
$$
Nomeadamente, conjuntos da forma
$$
D_3 = \{ (x,y,z) \in \R^n: l<x<r; l_1(x) < y < u_1(x); l_2(x, y) < z < u_2(x,y) \}
$$
$$
D_2 = \{ (x,y) \in \R^n: l<x<r; l_1(x) < y < u_1(x) \}
$$
em que $l_i, u_i$ são funções $\R^i \to \R$, têm volume
$$
vol_3(D_3) = \int_l^u \left( \int_{l_1(x)}^{u_1(x)} \left( \int_{l_2(x,y)}^{u_2(x,y)} 1 \, dz \right) dy \right) dx
$$
$$
vol_2(D_2) = \int_l^u \left( \int_{l_1(x)}^{u_1(x)} 1 \, dx \right) dx
$$
Para generalizar este resultado para dimensões, definimos um \textbf{corte} perpendicular ao eixo $x_k$ como um conjunto
$$
C(x_k) = D \cap \{ (x_1, x_2, \cdots, x_n) \in \R^n : x_k = c (c \in \R \}
$$
Desta forma, vemos que o volume de um conjunto 
$$
D = \{ (x,y) \in \R^{n-1} \times \R: x \in C(y) ; a < y < b \}
$$ 
pode ser definido da seguinte forma:
$$
vol_n(D) = \int_a^b vol_{n-1}(C(y)) dy
$$

\subsection{Aplicações dos Integrais}
O uso mais frequente e famoso de integrais é para calcular áreas/volumes. No entanto, os integrais podem ser usados para calcular outras entidades físicas muito relevantes. Nomeadamente:
\begin{itemize}
	\item \textbf{Massa}:\\
Seja $\sigma: D \to \R$ uma função que representa a densidade de um sólido representado por $D \subset \R^n$. Então, a massa do sólido é dada por
$$
\int_D \sigma
$$
Note-se que se $\sigma$ é constante ($\sigma(x) = \rho, \forall x \in D$), temos que $M = V \cdot \rho$.
	\item \textbf{Centro de Massa}:\\
Recuperando a função densidade $\sigma: D \to \R$ do sólido representado por $D$, temos que o centro de massa do sólido é dado por
$$
\overline{x} = (\overline{x_1}, \overline{x_2}, \cdots, \overline{x_n})
$$
tal que, para qualquer $i \in \{1, 2, \cdots, n \}$
$$
\overline{x_i} = \frac{\int_D x_i \sigma(x)}{\int_D \sigma(x)} = \frac{1}{M} \int_D x_i \sigma(x)
$$
No caso em que $\sigma$ vale 1 em todos os pontos, a este ponto dá-se também o nome de \textbf{centróide}.
	\item \textbf{Momento de Inércia}:\\
Seja $L$ uma linha reta e $d_L(x)$ a distância do ponto $x \in \R^n$ à linha $L$. O momento de inércia do conjunto $D$ relativo à reta $L$, é dado por
$$
I_L = \int_D \sigma(x) d_L(x)^2
$$
em que $\sigma$ é mais uma vez a função densidade do sólido representado por $D$.
\end{itemize}

\subsection{Mudança de variável e Regra de Leibniz}
Defina-se \textbf{mudança de variável} como uma função injetiva $\varphi: D \subset \R^n \to \R^n$ de classe $C^1$ e não nula em $D$. 

\textbf{Teorema da mudança de variável}:\\
Seja $\varphi: D \to \R^n$ uma mudança de variável de domínio aberto limitado tal que $f$ é um campo escalar de domínio $X=\varphi(D)$. Então
$$
\int_X f(x) \, dx = \int_D f(\varphi(t)) |\text{det} D \varphi(t)| \, dt
$$
Este teorema é muito útil para aproveitar certas simetrias da função $f$. Mudanças de variáveis comuns são:
\begin{itemize}
	\item \textbf{Coordenadas Polares}: Para uma função em $\R^2$.
	$$ \varphi (x,y) = (r \cos \theta, r \sin \theta) $$
	($r \in \R^+, \theta \in [0, 2\pi[$) aproveita simetrias circulares em torno da origem. Tem-se que $|D\varphi(x,y)| = r$.
	\item \textbf{Coordenadas Cilíndricas}: Para uma função em $\R^3$.
	$$ \varphi(x,y,z) = (r \cos \theta, r \sin \theta, z) $$
	($r \in \R^+, \theta \in [0,2\pi[, z \in \R$) aproveita simetrias cilíndricas em torno do eixo $Oz$. Tem-se que $|D\varphi(x,y)| = r$.
	\item \textbf{Coordenadas Esféricas}: Para uma função $\R^3$.
	$$ \varphi (x,y,z) = (r \sin \phi \cos \theta, r\sin \phi \sin \theta, r \cos \phi)	$$
	($r \in \R^+, \theta \in [0,2\pi[, \phi \in [0,\pi[$) aproveita simetrias esféricas em torno da origem. Tem-se que $|D\varphi(x,y)| = -r^2 \sin \phi$.
	\item \textbf{Transformações Lineares}: Seja $\varphi: \R^n \to \R^n$ uma transformação linear representada pela matriz $A$ ($\varphi(x) = Ax, \forall \, x \in \R$). Como qualquer transformação linear é de classe $C^1$, temos que $\varphi$ é uma mudança de variável desde que $|A| \neq 0$.\\
	Este tipo de mudanças de variável são úteis para facilitar contas, deslocando a origem do referencial ou alinhando os eixos coordenados com retas relevantes, por exemplo. Tem-se que $|D\varphi(x)|=|A|$. 
\end{itemize}
Finalmente, se nenhuma das técnicas até agora estudadas for suficiente para calcular um integral, a \textbf{regra de Leibniz} oferece-se nos uma forma de calcular a derivada de um integral que não pode ser diretamente calculado.\\
Seja $f: I \subset \R^n \to \R$ de classe $C^1$ no seu domínio compacto e seja 
$$
F(x) = \int_I f(t,x) \, dt
$$
ao integral a cima dá-se o nome de \textbf{integral paramétrico} em que a variável $x$ desempenha o papel de parâmetro (é constante no integral).

A regra de Leibniz dá-nos que
$$
\frac{\partial F}{\partial x_k} (x) = \int_{a_k}^{b_k} \frac{\partial f}{\partial x_k} (t,x) \, dt
$$
para qualquer $k \in \{ 1, 2, \cdots , n \}$.

Mais genericamente, usando a regra da cadeia podemos derivar integrais parmétricos da forma
$$
F(x) = \int_{\phi(x)}^{\psi(x)} f(t,x) \, dt
$$
Considerando $F(x) = G(x, \phi(x), \psi(x))$ em que $G: \R^3 \to \R$ é dado por $G(x,u,v) = \int_u^v f(t,x) \, dt$ temos que, segundo a regra da cadeia:
$$
F'(x) = \frac{\partial G}{\partial x} + \frac{\partial G}{\partial u}\phi '(x) + \frac{\partial G}{\partial v} \psi '(x) = \int_{\phi(x)}^{\psi(x)} \frac{\partial f}{\partial x}(t,x) \, dt + f(\psi(x), x)\psi'(x) - f(\phi(x),x)\phi'(x)  
$$

\section{Integrais sobre Variedades}

\subsection{Integrais de Campos Escalares sobre Variedades}
Definimos o integral de um campo escalar $\phi: \R^n \to \R$ sobre uma $p$-variedade como sendo o integral
$$ \int_S \phi = \int_T \phi(g(t)) \sqrt{\det Dg(t)^T Dg(t)} \, dt $$
em que $g: T \subset \R^p \to \R^n$ é uma parametrização de $S$.

Esta noção tem as seguintes aplicações práticas:
\begin{itemize}
	\item \textbf{p-Volume de uma p-Variedade}\\
	Para $\phi = 1$ o integral $\phi$ numa variedade $S$ dá
	$$ vol_p(S) = \int_S \phi $$ 
	\item \textbf{Massa de uma p-Variedade}\\
	Se pensarmos em $\phi$ como a função densidade da variedade, o integral de de $\phi$ sobre a variedade dá a massa dessa variedade.
	\item \textbf{Centro de Massa}\\
	O centro de massa de uma p-variedade S com densidade $\phi$ é da forma $(\overline{x_1}, \overline{x_2}, \cdots, \overline{x_n})$ de forma que
	$$ \overline{x_i} = \int_S \frac{1}{M}x_i \phi(x) $$
	\item \textbf{Momento de Inércia}\\
	Dada uma reta $L$ e a função $d_L(x)$ a distância do ponto $x \in \R^n$ à linha $L$. O momento de inércia de uma p-variedade a $L$ é o integral
	$$ I_L = \int_S \phi(x)d_L^2(x) $$
	em que $\phi$ é a função densidade de $S$.
\end{itemize}

Nomeadamente, para 1-variedades, temos que $\sqrt{Dg(t)^T Dg(t)}$ é o produto vetorial $g'(t) \cdot g'(t) = ||g'(t)||$ e definimos este caso particular como um integral de linha:\\
Se $\Gamma$ for uma linha definida por um caminho $\gamma : [a,b] \to \R^n$, ao integral de um campo escalar $\phi : \R^n \to \R$ sobre a variedade $\Gamma$ dá-se o nome de \textbf{integral de linha}:
$$ \int_\Gamma \phi = \int_a^b \phi(\gamma(t)) || \gamma'(t) || \, dt $$

\subsection{Integrais de Campos Vetoriais}
Seja $S \subset \R^n$ um aberto, $F: S \to \R^n$ um campo vetorial e $\Gamma \subset S$ uma linha descrita pelo caminho $\gamma: [a,b] \to \R^n$, de classe $C^1$. Ao integral
$$ \int_\Gamma F \cdot d\gamma = \int_a^b F(\gamma(t))\cdot \gamma '(t) \, dt$$
chama-se \textbf{integral de linha} do campo vetorial $F$ ao longo do caminho $\gamma$.

Note-se que:
$$ \int_\Gamma F \cdot d\gamma = \int_a^b F(\gamma(t))\cdot \frac{\gamma'(t)}{||\gamma'(t)||} \cdot ||\gamma'(t)|| \, dt = \int_\Gamma F\cdot t  $$
em que $t$ é um vetor tangente a $\Gamma$ em cada ponto e $F \cdot t$ é um campo escalar, pelo que obtemos um integral de linha de um campo escalar como introduzido no último capítulo.\\ 

\newpage
Observações:
\begin{itemize}
	\item Uma vez que a representação matemática de uma força física é um campo vetorial, o \textbf{trabalho} de uma força sobre uma partícula a descrever uma trajetória representada por uma linha $\Gamma$ é dada pelo integral de linha da força sobre essa linha; 
	\item Se $\gamma_1$ e $\gamma_2$ são duas parametrizações de $\Gamma$ que percorrem a curva no mesmo sentido, o integral $\int_\Gamma F \cdot d\gamma_1 = \int_\Gamma F \cdot d\gamma_2$, e se percorrerem $\Gamma$ em sentidos opostos então $\int_\Gamma F \cdot d\gamma_1 = -\int_\Gamma F \cdot d\gamma_2$; 
	\item O valor do integral de uma linha entre dois pontos depende da linha e não apenas dos extremos.
\end{itemize}

\subsection{Tipos de Campos Vetoriais e Teorema Fundamental do Cálculo}
Por vezes calcular um integral de linha diretamente pela definição pode ser difícil. Há no entanto algumas propriedades dos campos vetoriais que nos podem facilitar a vida. Definimos então:
\begin{itemize}
	\item Dizemos que uma curva é \textbf{fechada} se os seus pontos inicial e final coincidirem. Os integrais sobre curvas fechadas são denotados por
$$ \oint_\Gamma F \cdot \, d \gamma $$
	\item Dizemos que um caminho é \textbf{regular} se for de classe $C^1$;
	\item Dizemos que um campo vetorial é \textbf{conservativo} num domínio $D$ se o seu integral sobre qualquer curva em $D$ depende apenas dos extremos;
	\item Dizemos que um campo vetorial $F: \R^n \to \R^n$ é \textbf{gradiente} se houver $\phi: \R^n \to \R$ de classe $C^1$ tal que $F = \nabla \phi$. Nesse caso dizemos que $\phi$ é o \textbf{potencial escalar} de $F$;
	\item Dizemos que um campo $F: \R^n \to \R^n$ é \textbf{fechado} se satisfizer:
	$$ \frac{\partial F_i}{\partial x_j} = \frac{\partial F_j}{\partial x_i} $$
\end{itemize}

\textbf{Teorema Fundamental do Cálculo}\\
Se $\varphi:\R^n \to \R$ de classe $C^1$ estvire definida na linha $\Gamma$ definida por $\gamma:[a,b] \to \R^n$ com extremos $A = \varphi(a)$ e $B = \varphi(b)$, então:
$$ \int_\Gamma \nabla \varphi \cdot dg = \varphi(B) - \varphi(A) $$
A partir do teorema a cima e das relações a cima podemos concluir que:
\begin{itemize}
	\item Um campo é \textbf{gradiente se e só se for conservativo};
	\item Qualquer campo \textbf{gradiente/conservativo é fechado};
	\item Se $F$ for um campo conservativo, segundo o TFC temos que
	$$ \oint_\Gamma F \cdot \gamma = 0 $$
\end{itemize}

O cálculo do trabalho de um campo gradiente fica assim muito simplificado, desde que seja numa curva fechada, ou o seu potencial seja conhecido.

O potencial de um campo vetorial é obtido primitivando as funções coordenadas desse campo. 

Em relação às definições a cima, fica apenas a faltar saber em que circunstâncias é que um campo fechado é conservativo.

Para isto definimos duas curvas $C_1$ e $C_2$ num domínio $D$ como \textbf{homotópicas} se e só se for possível obter $C_2$ através de uma deformação de $C_1$, se essa deformação mantiver todos os pontos de $C_2$ em $D$.

Temos que o integral de linha de um campo vetorial fechado sobre duas curvas fechadas homotópicas é o mesmo.

Definimos agoa um conjunto $D$ como \textbf{simplesmente conexo} se qualquer curva em $D$ for homotópica a um ponto.

Temos então que qualquer campo \textbf{fechado num domínio simplesmente conexo é gradiente}.

\subsection{Teorema de Green}
Se $F=(F_1,F_2): A \subset \R^2 \to \R^2$ for de classe $C^1$ num domínio quase regular $\overline{D} \subset A$, então
$$
\oint_{\partial D} F \cdot dg = \iint_D \frac{\partial F_2}{\partial x} - \frac{\partial F_1}{\partial y} dx dy
$$
em que a linha $\partial D$ é percorrida no sentido canónico: o sentido tal que $D$ fica à esquerda de uma trajetória segundo esse sentido.

É evidente que se $F$ for um campo fechado, o seu integral sobre uma linha fechada que limita um domínio regular é nula. De forma semelhante, podemos concluir a partir deste teorema que o trabalho de um campo vetorial de classe $C^1$ e fechado sobre duas curvas num domínio regular, percorridas no mesmo sentido, é igual.

\subsection{Teorema da Divergência}
Definimos uma variedade bi-dimensional $S \subset \R^3$ como \textbf{orientável} se existir um campo vetorial $n: A \subset \R^3 \to \R^3$ contínuo tal que $n(x)$ é um vetório unitário normal a $S$ ($S \subset A$). Diz-se que $n$ é ou define uma \textbf{orientação de $S$}. Nota-se que qualquer variedade bi-dimensional é orientável localmente.

Dada qualquer variedade bi-dimensional $S \subset \R^3$ com orientação $n$ e definida por uma parametrização $g:T \subset \R^2 \to \R^3$ e $F: A \to \R^3$ um campo vetorial definido num aberto tal que $S \subset A$, definimos o \textbf{fluxo de $F$ em $S$} como o valor do integral
$$ \int_S F \cdot n 
= \int_T F(g(t)) \cdot n(g(t)) \cdot \sqrt{\det Dg(t)^T Dg(t)} \, dt 
= \int_T F(g(u,v)) \cdot \left( \frac{\partial g}{\partial u} \times 
\frac{\partial g}{\partial v} \right) du dv$$

Definimos agora a \textbf{divergência} de um campo vetorial $F: S \to \R^3$ de classe $C^1$ no aberto $S$ como o campo escalar
$$ \text{div } F = \nabla \cdot F = \frac{\partial F_1}{\partial x} + \frac{\partial F_2}{\partial y} + \frac{\partial F_3}{\partial z} $$
Definimos ainda um \textbf{domínio regular} $D \subset \R^3$ se e só a sua fronteira $\partial D$ é uma união finita de superfícies orientáveis.\\
Com estas definições, enunciamos então o \textbf{Teorema da divergência}:\\
Se $D \subset \R^3$ for um domínio regular e $n$ a normal em $\partial D$ que aponta para fora de $D$, então
$$ \int_{\partial D} F \cdot n = \iiint_D \text{div } F $$

\subsection{Teorema de Stokes}
Seja $S$ uma superfície em $\R^3$ parametrizada por $g: D \to \R^3$, tal que $g$ está definida num aberto $A \subset \R^2$ tal que $\overline{D} \subset A$. Se $\partial D$ for uma linha simples e fechada descrita por um caminho $\gamma: [a,b] \to \R^2$, definimos o \textbf{bordo} da superfície $S$ à linha descrita pelo caminho $g \circ \gamma$, ou seja
$$ \partial S = g(\partial D) = g(\gamma([a,b])) $$
Diz-se que a orientação de percurso da linha $\partial X$ é \textbf{compatível} com a orientação de $S$ se satisfizer a regra da mão direita.

Definimos ainda o \textbf{rotacional} de $F$ como o campo vetorial:
$$ \text{rot} F = \nabla \times F = \left( 
\frac{\partial F_3}{\partial y} - \frac{\partial F_2}{\partial z},
\frac{\partial F_1}{\partial z} - \frac{\partial F_3}{\partial x},
\frac{\partial F_2}{\partial x} - \frac{\partial F_1}{\partial y} 
\right) $$
é claro pela definição que a rotação de um campo fechado é nula. Neste caso diz-se também que o campo é \textbf{irrotacional}.

Diz então o \textbf{teorema de Stokes} que para qualquer campo vetorial $F: A \subset \R^3 \to \R^3$ de classe $C^1$ no aberto $A$ e $S \subset \R^3$ uma variedade bi-dimensional orientável tal que $S \cup \partial S \subset A$, se tem que
$$ \iint_S \text{rot} F \cdot n = \int_{\partial S} F \cdot d \gamma $$
em que $\gamma$ é um caminho regular que descreve $\partial S$ com orientação compatível com a de $S$.

Observamos que o Teorema de Stokes pode ser então usado para três tipos de problemas:
\begin{itemize}
	\item Determinar o fluxo do rotacional de um campo numa superfície através do trabalho desse campo no bordo da superfície;
	\item Determinar o trabalho de um campo numa linha fechada através do fluxo do rotacional desse campo numa superfície cujo bordo é (ou contém, mais genericamente) essa linha.
	\item Determinar o fluxo de um campo vetorial $F$ sobre uma superfície. Neste caso, o problema torna-se determinar outro campo vetorial cujo rotacional seja $F$.
\end{itemize}

Vamos então focar-nos na última das três aplicações indicadas a cima do teorema. Dizemos que o campo vetorial $A: \Omega \subset \R^3 \to \R^3$ é um \textbf{potencial vetorial} de $F: \Omega \subset \R^3 \to \R^3$ ($\Omega$ é um aberto) se e só se $F = \text{rot} A$.\\
Observando que $\text{div}(\text{rot}(F)) = 0$, para qualquer campo vetorial $F$, verificamos que $\text{div}F = 0$ é uma condição necessária para que $F$ tenha um potencial vetorial.\\
Definimos um conjunto $D \subset \R^3$ como \textbf{estrelado} ou \textbf{em estrela} se houver um ponto $a \in A$ tal que o segmento $ab$ está contido em $A$ para todo o $b \in A$.\\
Temos que qualquer campo vetorial $G: A \subset \R^3 \to \R^3$ com divergência nula e domínio aberto e estrela tem um potencial vetorial.\\
Note-se que qualquer conjunto estrelado é simplesmente conexo, mas a implicação contrária não se mantém.\\
Temos então de arranjar uma maneira de calcular o potencial vetorial de um campo vetorial.\\
Para isto observamos que, como $\nabla \phi$ é fechado para qualquer $\phi: \Omega \to \R$ de classe $C^2$, então rot$(\nabla \phi) = 0$ e 
$$ \text{rot}(F+\nabla \phi) = \text{rot}(F) + \text{rot}(\nabla \phi) = \text{rot}(F) $$
Considerando então $\phi(x,y,z) = -\int_0^z A_3(x,y,t) \, dt$, temos que a equação rot$(A+\nabla \phi) = F$ se traduz no sistema
\begin{align*}
-\frac{\partial A_2}{\partial z} &= F_1(x,y,z) \\
\frac{\partial A_1}{\partial z} &= F_2(x,y,z) \\
\frac{\partial A_2}{\partial x} - \frac{\partial A_1}{\partial y} &= F_3(x,y,z)
\end{align*}
que podes ser resolvido para determinar as funções $A_1$ e $A_2$. Note-se que anulámos a terceira função coordenada de $A$, mas podíamos ter optado pela primeira ou segunda.

\end{document}
